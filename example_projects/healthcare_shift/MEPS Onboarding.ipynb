{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arthurai import ArthurAI\n",
    "from arthurai.client.apiv3 import InputType, OutputType, Stage, AttributeCategory, AttributeBin, ValueType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up connection to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"app.arthur.ai\"\n",
    "ACCESS_KEY = \"\"\n",
    "\n",
    "connection = ArthurAI(url=URL, access_key=ACCESS_KEY, client_version=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = connection.model(partner_model_id=\"MEPS_drift_1\",\n",
    "                         input_type=InputType.Tabular,\n",
    "                         output_type=OutputType.Multiclass,\n",
    "                         is_batch=True)\n",
    "\n",
    "# uncomment the below if you want to get the same model object that you have already created\n",
    "# model = connection.get_model('MEPS_drift_1', id_type='partner_model_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up ArthurModel\n",
    "Everything under this header is *necessary* for an `ArthurModel` to be created; additional functionality is not \n",
    "possible until after `model.save()` has been successfully called.\n",
    "\n",
    "*Some context about this dataset:*\n",
    "\n",
    "- label: `UTILIZATION`, where 1: >10 visits, 0: <10 visits\n",
    "\n",
    "- protected attribute: `RACE`, where 1: `White`, 0: `Non-White`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_data_full contains the X's and the Y's\n",
    "all_data = pd.read_parquet('data/fulldata_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick summary of what all_data looks like\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.columns.tolist()[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the attributes used for training to the model and set them to ModelPipelineInput\n",
    "# note that attribute names need to contain only letters, numbers, and underscores, and cannot begin with a number\n",
    "train_x = all_data.drop(columns=['RACE','p_0', 'p_1', 'gt'])\n",
    "model.from_dataframe(train_x, Stage.ModelPipelineInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_<>_utilization will refer to the ground truth values (i.e. true labels), while\n",
    "# pred_<>_utilization will refer to the predicted outputs of your model. \n",
    "pred_to_ground_truth_map = {\n",
    "    \"pred_high_utilization\": \"gt_high_utilization\",\n",
    "    \"pred_low_utilization\": \"gt_low_utilization\"\n",
    "}\n",
    "\n",
    "# add the ground truth and predicted attributes to the model\n",
    "model.add_binary_classifier_output_attributes('pred_high_utilization', pred_to_ground_truth_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bias monitoring - this cannot be done after the model is saved\n",
    "# to monitor for bias, 'RACE' must be an int (or take on discrete string values)\n",
    "all_data['RACE'] = all_data['RACE'].astype(int)\n",
    "sens_x = pd.DataFrame(data={'RACE': all_data['RACE']})\n",
    "model.from_dataframe(sens_x, Stage.NonInputData)\n",
    "\n",
    "model.get_attribute('RACE', stage=Stage.NonInputData).monitor_for_bias=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all the attributes loaded to the model. note that even though you passed in your \"real\" training\n",
    "# data, currently the model has no reference to the actual datapoints -- just the properties of the \n",
    "# attributes. you will need to set reference data (for data drift detection) later\n",
    "model.review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your model is not uploaded to Arthur until you call model.save()\n",
    "model.save()\n",
    "# model.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding additional functionality\n",
    "\n",
    "Setting reference data and monitoring for bias adds to the functionality of the `ArthurModel` that you've created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting reference data\n",
    "\n",
    "Now that we've saved the model, we can set reference data.\n",
    "The reference data df must have a column for each `ModelPipelineInput` and each `NonInput`. Optionally, it \n",
    "can contain predicted value and ground truth columns; this will enable the calculation of data drift \n",
    "on output attributes. In this model, our ground truth columns are `gt_high_utilization` and `gt_low_utilization`,\n",
    "and our predicted value columns are `pred_high_utilization` and `pred_low_utilization`. \n",
    "\n",
    "We need to rename and update the columns in `all_data` to match these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['p_0', 'p_1', 'gt']\n",
    "all_data = all_data.rename(columns={'p_0': 'pred_low_utilization', 'p_1': 'pred_high_utilization'})\n",
    "gt = pd.get_dummies(all_data['gt'], prefix='gt', dtype='int')\n",
    "gt = gt.rename(columns={'gt_0.0': 'gt_low_utilization', 'gt_1.0': 'gt_high_utilization'})\n",
    "all_data = all_data.drop(columns=['gt'])\n",
    "all_data = all_data.merge(gt, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_reference_data(data=all_data) # note: need to explicitly specify the data= argument"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### send batches of inferences\n",
    "\n",
    "We do not need to load/expose the actual predictive model to send inferences to `arthur_model`. `x_shift` is a directory holding batched data. Each of the parquet files is a dataframe with the following columns:\n",
    "\n",
    "- sensitive attribute, `RACE`\n",
    "- all attributes used for training\n",
    "- `p_0`: the predicted probability of this example being in the 0 class - *given by your model*\n",
    "- `p_1`: the predicted probability of this example being in the 1 class - *given by your model*\n",
    "- `gt`: the ground truth label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls x_shift "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### batch inference format\n",
    "(df option)\n",
    "Your batch inferences must have the dummied prediction columns that you created earlier; \n",
    "if you don't have ground truth labels at this time, you don't need to send them now.\n",
    "When sending batch inferences, you must add the following additional columns: \n",
    "- `batch_id` - string\n",
    "- `partner_inference_id`- string\n",
    "- `inference_timestamp` - datetime.datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4): # sending inferences without ground truth\n",
    "    alldata = pd.read_parquet('data/x_shift/fulldata_'+str(i) +'.parquet')\n",
    "    tosend = alldata.rename(columns={'p_0': 'pred_low_utilization', 'p_1': 'pred_high_utilization'})\n",
    "    tosend['RACE'] = tosend['RACE'].astype(int)\n",
    "    \n",
    "    tosend['batch_id'] = [str(i)]*len(tosend)\n",
    "    tosend['partner_inference_id'] = [str(np.random.randint(10000))]*len(tosend)\n",
    "    tosend['inference_timestamp'] = [(datetime.now())]*len(tosend)\n",
    "    \n",
    "    model.send_batch_inferences(data=tosend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4): # adding ground truth later\n",
    "    alldata = pd.read_parquet('data/x_shift/fulldata_'+str(i) +'.parquet')\n",
    "    tosend = pd.get_dummies(alldata['gt'], prefix='gt')\n",
    "    tosend = tosend.rename(columns={'gt_0.0': 'gt_low_utilization', 'gt_1.0': 'gt_high_utilization'})\n",
    "\n",
    "    tosend['batch_id'] = [str(i)]*len(tosend)\n",
    "    tosend['partner_inference_id'] = [str(np.random.randint(10000))]*len(tosend)\n",
    "    tosend['inference_timestamp'] = [(datetime.now())]*len(tosend)\n",
    "    \n",
    "    model.send_batch_inferences(data=tosend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4): # adding gt and infs at the same time\n",
    "    alldata = pd.read_parquet('data/x_shift/fulldata_'+str(i+4) +'.parquet')\n",
    "    tosend = alldata.rename(columns={'p_0': 'pred_low_utilization', 'p_1': 'pred_high_utilization'})\n",
    "    tosend['RACE'] = tosend['RACE'].astype(int)\n",
    "    \n",
    "    gts = pd.get_dummies(alldata['gt'], prefix='gt')\n",
    "    gts = gts.rename(columns={'gt_0.0': 'gt_low_utilization', 'gt_1.0': 'gt_high_utilization'})\n",
    "    \n",
    "    tosend = tosend.merge(gts, left_index=True, right_index=True)\n",
    "\n",
    "    tosend['batch_id'] = [str(i+4)]*len(tosend)\n",
    "    tosend['partner_inference_id'] = [str(np.random.randint(10000))]*len(tosend)\n",
    "    tosend['inference_timestamp'] = [(datetime.now())]*len(tosend)\n",
    "    \n",
    "    model.send_batch_inferences(data=tosend)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
