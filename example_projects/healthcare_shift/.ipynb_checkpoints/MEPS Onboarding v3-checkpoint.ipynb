{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arthurai import ArthurAI\n",
    "from arthurai.client.apiv3 import InputType, OutputType, Stage, AttributeCategory, AttributeBin, ValueType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up connection to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"v3.dev.arthur.ai\"\n",
    "ACCESS_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdXRob3JpemVkIjp0cnVlLCJjb250ZXh0cyI6W3siY29udGV4dF9pZCI6IjRmMjk0NmE0LWExZjUtNDY4Mi04NDc5LTc5ZDJiNWE5MTkzYyIsImNvbnRleHRfdHlwZSI6Ik9yZ2FuaXphdGlvbiIsInJvbGUiOiJNb2RlbCBPd25lciJ9XSwiZXhwIjoxNjU3ODI0MTIwfQ.HCagGKGZmE8_F638BDeYTpR0W2DWrGPd4e_b81_p5s4\"\n",
    "\n",
    "connection = ArthurAI(url=URL, access_key=ACCESS_KEY, client_version=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = connection.model(partner_model_id=\"MEPS_drift_2\",\n",
    "                         input_type=InputType.Tabular,\n",
    "                         output_type=OutputType.Multiclass,\n",
    "                         is_batch=True)\n",
    "\n",
    "# model = connection.get_model('MEPS_drift_1', id_type='partner_model_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up ArthurModel\n",
    "Everything under this header is *necessary* for an `ArthurModel` to be created; additional functionality is not \n",
    "possible until after `model.save()` has been successfully called.\n",
    "\n",
    "*Some context about this dataset:*\n",
    "\n",
    "- label: `UTILIZATION`, where 1: >10 visits, 0: <10 visits\n",
    "\n",
    "- protected attribute: `RACE`, where 1: `White`, 0: `Non-White`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_data_full contains the X's and the Y's\n",
    "all_data = pd.read_parquet('fulldata_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['p_0', 'p_1', 'gt']"
      ],
      "text/plain": [
       "['p_0', 'p_1', 'gt']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns.tolist()[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the attributes used for training to the model and set them to ModelPipelineInput\n",
    "# note that attribute names need to contain only letters, numbers, and underscores, and cannot begin with a number\n",
    "train_x = all_data.drop(columns=['RACE','p_0', 'p_1', 'gt'])\n",
    "model.from_dataframe(train_x, Stage.ModelPipelineInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_x = pd.DataFrame(data={'RACE': all_data['RACE']})\n",
    "model.from_dataframe(sens_x, Stage.NonInputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_high_utilization': <arthurai.client.apiv3.attributes.ArthurAttribute at 0x7ffc9fb29ca0>,\n",
       " 'gt_high_utilization': <arthurai.client.apiv3.attributes.ArthurAttribute at 0x7ffc9fad6a30>,\n",
       " 'pred_low_utilization': <arthurai.client.apiv3.attributes.ArthurAttribute at 0x7ffc9fb29cd0>,\n",
       " 'gt_low_utilization': <arthurai.client.apiv3.attributes.ArthurAttribute at 0x7ffc9fb35070>}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gt_<>_utilization will refer to the ground truth values (i.e. true labels), while\n",
    "# pred_<>_utilization will refer to the predicted outputs of your model. \n",
    "pred_to_ground_truth_map = {\n",
    "    \"pred_high_utilization\": \"gt_high_utilization\",\n",
    "    \"pred_low_utilization\": \"gt_low_utilization\"\n",
    "}\n",
    "\n",
    "# add the ground truth and predicted attributes to the model\n",
    "model.add_binary_classifier_output_attributes('pred_high_utilization', pred_to_ground_truth_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>stage</th>\n",
       "      <th>value_type</th>\n",
       "      <th>categorical</th>\n",
       "      <th>is_unique</th>\n",
       "      <th>categories</th>\n",
       "      <th>range</th>\n",
       "      <th>monitor_for_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt_high_utilization</td>\n",
       "      <td>GROUND_TRUTH</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 0}, {value: 1}]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gt_low_utilization</td>\n",
       "      <td>GROUND_TRUTH</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 0}, {value: 1}]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RACE</td>\n",
       "      <td>NON_INPUT_DATA</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGE</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0, 85.0]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCS42</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-9.0, 62.56]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>INSCOV1</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>INSCOV2</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>INSCOV3</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>pred_high_utilization</td>\n",
       "      <td>PREDICTED_VALUE</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>pred_low_utilization</td>\n",
       "      <td>PREDICTED_VALUE</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name            stage value_type categorical is_unique  \\\n",
       "0      gt_high_utilization     GROUND_TRUTH    INTEGER        True     False   \n",
       "1       gt_low_utilization     GROUND_TRUTH    INTEGER        True     False   \n",
       "2                     RACE   NON_INPUT_DATA      FLOAT       False     False   \n",
       "3                      AGE   PIPELINE_INPUT      FLOAT       False     False   \n",
       "4                    PCS42   PIPELINE_INPUT      FLOAT       False     False   \n",
       "..                     ...              ...        ...         ...       ...   \n",
       "137                INSCOV1   PIPELINE_INPUT      FLOAT       False     False   \n",
       "138                INSCOV2   PIPELINE_INPUT      FLOAT       False     False   \n",
       "139                INSCOV3   PIPELINE_INPUT      FLOAT       False     False   \n",
       "140  pred_high_utilization  PREDICTED_VALUE      FLOAT       False     False   \n",
       "141   pred_low_utilization  PREDICTED_VALUE      FLOAT       False     False   \n",
       "\n",
       "                   categories          range monitor_for_bias  \n",
       "0    [{value: 0}, {value: 1}]   [None, None]            False  \n",
       "1    [{value: 0}, {value: 1}]   [None, None]            False  \n",
       "2                          []     [0.0, 1.0]            False  \n",
       "3                          []    [0.0, 85.0]            False  \n",
       "4                          []  [-9.0, 62.56]            False  \n",
       "..                        ...            ...              ...  \n",
       "137                        []     [0.0, 1.0]            False  \n",
       "138                        []     [0.0, 1.0]            False  \n",
       "139                        []     [0.0, 1.0]            False  \n",
       "140                        []         [0, 1]            False  \n",
       "141                        []         [0, 1]            False  \n",
       "\n",
       "[142 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check all the attributes loaded to the model. note that even though you passed in your \"real\" training\n",
    "# data, currently the model has no reference to the actual datapoints -- just the properties of the \n",
    "# attributes. you will need to set reference data (for data drift detection) later\n",
    "model.review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c0c2a18d-ec87-4b8f-a9af-165543a0c4f4'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your model is not uploaded to Arthur until you call model.save()\n",
    "model.save()\n",
    "# model.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding additional functionality\n",
    "\n",
    "Setting reference data and monitoring for bias adds to the functionality of the `ArthurModel` that you've created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting reference data\n",
    "\n",
    "Now that we've saved the model, we can set reference data.\n",
    "The reference data df must have a column for each `ModelPipelineInput` and each `NonInput`. Optionally, it \n",
    "can contain predicted value and ground truth columns; this will enable the calculation of data drift \n",
    "on output attributes. In this model, our ground truth columns are `gt_high_utilization` and `gt_low_utilization`,\n",
    "and our predicted value columns are `pred_high_utilization` and `pred_low_utilization`. \n",
    "\n",
    "We need to rename and update the columns in `all_data` to match these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['p_0', 'p_1', 'gt']\n",
    "all_data = all_data.rename(columns={'p_0': 'pred_low_utilization', 'p_1': 'pred_high_utilization'})\n",
    "gt = pd.get_dummies(all_data['gt'], prefix='gt', dtype='int')\n",
    "gt = gt.rename(columns={'gt_0.0': 'gt_low_utilization', 'gt_1.0': 'gt_high_utilization'})\n",
    "all_data = all_data.drop(columns=['gt'])\n",
    "all_data = all_data.merge(gt, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE                      float64\n",
       "RACE                     float64\n",
       "PCS42                    float64\n",
       "MCS42                    float64\n",
       "K6SUM42                  float64\n",
       "                          ...   \n",
       "INSCOV3                  float64\n",
       "pred_low_utilization     float64\n",
       "pred_high_utilization    float64\n",
       "gt_low_utilization         int64\n",
       "gt_high_utilization        int64\n",
       "Length: 142, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'counts': {'success': 161, 'failure': 0, 'total': 161}, 'failures': [[]]}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_reference_data(data=all_data) # note: need to explicitly specify the data= argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting bias monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_attribute('RACE', stage=Stage.NonInputData).monitor_for_bias=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### send batches of inferences\n",
    "\n",
    "We do not need to load/expose the actual predictive model to send inferences to `arthur_model`. `x_shift` is a directory holding batched data. Each of the parquet files is a dataframe with the following columns:\n",
    "\n",
    "- sensitive attribute, `RACE`\n",
    "- all attributes used for training\n",
    "- `p_0`: the predicted probability of this example being in the 0 class - *given by your model*\n",
    "- `p_1`: the predicted probability of this example being in the 1 class - *given by your model*\n",
    "- `gt`: the ground truth label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mfulldata_0.parquet\u001b[0m*  \u001b[01;32mfulldata_3.parquet\u001b[0m*  \u001b[01;32mfulldata_6.parquet\u001b[0m*\r\n",
      "\u001b[01;32mfulldata_1.parquet\u001b[0m*  \u001b[01;32mfulldata_4.parquet\u001b[0m*  \u001b[01;32mfulldata_7.parquet\u001b[0m*\r\n",
      "\u001b[01;32mfulldata_2.parquet\u001b[0m*  \u001b[01;32mfulldata_5.parquet\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls x_shift "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### batch inference format\n",
    "(df option)\n",
    "Your batch inferences must have the dummied prediction columns that you created earlier; \n",
    "if you don't have ground truth labels at this time, you don't need to send them now.\n",
    "When sending batch inferences, you must add the following additional columns: \n",
    "- `batch_id` - string\n",
    "- `partner_inference_id`- string\n",
    "- `inference_timestamp` - datetime.datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4): # sending inferences without ground truth\n",
    "    alldata = pd.read_parquet('x_shift/fulldata_'+str(i) +'.parquet')\n",
    "    infs = alldata[['p_0', 'p_1']]\n",
    "    tosend = infs.rename(columns={'p_0': 'pred_low_utilization', 'p_1': 'pred_high_utilization'})\n",
    "    \n",
    "    tosend['batch_id'] = [str(i)]*len(tosend)\n",
    "    tosend['partner_inference_id'] = [str(np.random.randint(10000))]*len(tosend)\n",
    "    tosend['inference_timestamp'] = [(datetime.now())]*len(tosend)\n",
    "    \n",
    "    model.send_batch_inferences(data=tosend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4): # adding ground truth later\n",
    "    alldata = pd.read_parquet('x_shift/fulldata_'+str(i) +'.parquet')\n",
    "    tosend = pd.get_dummies(alldata['gt'], prefix='gt')\n",
    "    tosend = tosend.rename(columns={'gt_0.0': 'gt_low_utilization', 'gt_1.0': 'gt_high_utilization'})\n",
    "\n",
    "    tosend['batch_id'] = [str(i)]*len(tosend)\n",
    "    tosend['partner_inference_id'] = [str(np.random.randint(10000))]*len(tosend)\n",
    "    tosend['inference_timestamp'] = [(datetime.now())]*len(tosend)\n",
    "    \n",
    "    model.send_batch_inferences(data=tosend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4): # adding gt and infs at the same time\n",
    "    alldata = pd.read_parquet('x_shift/fulldata_'+str(i+4) +'.parquet')\n",
    "    infs = alldata[['p_0', 'p_1']]\n",
    "    tosend = infs.rename(columns={'p_0': 'pred_low_utilization', 'p_1': 'pred_high_utilization'})\n",
    "    \n",
    "    gts = pd.get_dummies(alldata['gt'], prefix='gt')\n",
    "    gts = gts.rename(columns={'gt_0.0': 'gt_low_utilization', 'gt_1.0': 'gt_high_utilization'})\n",
    "    \n",
    "    tosend = tosend.merge(gts, left_index=True, right_index=True)\n",
    "\n",
    "    tosend['batch_id'] = [str(i)]*len(tosend)\n",
    "    tosend['partner_inference_id'] = [str(np.random.randint(10000))]*len(tosend)\n",
    "    tosend['inference_timestamp'] = [(datetime.now())]*len(tosend)\n",
    "    \n",
    "    model.send_batch_inferences(data=tosend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c0c2a18d-ec87-4b8f-a9af-165543a0c4f4'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
