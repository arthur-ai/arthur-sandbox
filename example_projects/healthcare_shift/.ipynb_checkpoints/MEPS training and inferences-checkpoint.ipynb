{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pyarrow\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset. \n",
    "\n",
    "Pre-processed by `AIF360`'s `MEPS21` preprocessing. Medical Expenditures dataset.\n",
    "Prediction task: utilization of healthcare as quantified by # of visits to a healthcare provider. \n",
    "\n",
    "- label: `UTILIZATION`, where 1: >10 visits, 0: <10 visits\n",
    "- protected attribute: `RACE`, where 1: `White`, 0: `Non-White`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('data_raw/meps21_preprocessed.csv')\n",
    "\n",
    "X = all_data.copy().drop(columns=['UTILIZATION'])\n",
    "y = all_data.UTILIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nosens = X_train.copy().drop(columns=['RACE'])\n",
    "X_test_nosens = X_test.copy().drop(columns=['RACE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save a classifier. \n",
    "\n",
    "Note that the training is done on a version of the dataset *without* `RACE` as an attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jessica/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train_nosens, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8730057434588385"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train_nosens, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8525659200453644"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test_nosens, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['skl_lr.joblib']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'skl_lr.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = joblib.load('skl_lr.joblib')\n",
    "\n",
    "train_infs = pretrained.predict_proba(X_train.drop(columns=['RACE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save \"reference\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = X_train.columns.str.replace('[=]', '') \n",
    "X_train.columns = X_train.columns.str.replace('[-]', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_infs_df = pd.DataFrame(train_infs, columns=['p_0', 'p_1'])\n",
    "X_full = X_train.merge(train_infs_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full['gt'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full.to_parquet('fulldata_train.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and save 8 batches of shifted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one version of shift: 8 batches, only x-drift but 2 attributes are changing\n",
    "pretrained = joblib.load('skl_lr.joblib')\n",
    "\n",
    "pcsmus = np.arange(8)  # can do 8 separate batches here \n",
    "mcsmus = [0.5, 1.25, 2, 1, 0, -1, -2, -2]\n",
    "for i in range(8):\n",
    "    shifted_X = X_test[i*1763:(i+1)*1763].copy() \n",
    "    shape = len(shifted_X)\n",
    "    shifted_X['PCS42'] = shifted_X['PCS42'] + np.random.normal(pcsmus[i], 1, shape)\n",
    "    shifted_X['MCS42'] = shifted_X['MCS42'] + np.random.normal(mcsmus[i], 1, shape)\n",
    "    \n",
    "    infs = pretrained.predict_proba(shifted_X)\n",
    "    infs_df = pd.DataFrame(infs, columns=['p_0', 'p_1'])\n",
    "\n",
    "    shifted_X['gt'] = y_test[i*1763:(i+1)*1763].copy()\n",
    "    \n",
    "    shifted_X = shifted_X.merge(infs_df, left_index=True, right_index=True)\n",
    "    \n",
    "    shifted_X.to_parquet(\"x_shift/fulldata_\" + str(i) +\".parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mfulldata_0.parquet\u001b[0m*  \u001b[01;32mfulldata_3.parquet\u001b[0m*  \u001b[01;32mfulldata_6.parquet\u001b[0m*\r\n",
      "\u001b[01;32mfulldata_1.parquet\u001b[0m*  \u001b[01;32mfulldata_4.parquet\u001b[0m*  \u001b[01;32mfulldata_7.parquet\u001b[0m*\r\n",
      "\u001b[01;32mfulldata_2.parquet\u001b[0m*  \u001b[01;32mfulldata_5.parquet\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls x_shift"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
