{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arthurai import ArthurAI\n",
    "from arthurai.client.apiv3 import InputType, OutputType, Stage, AttributeCategory, AttributeBin, ValueType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up connection to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"app.arthur.ai\"\n",
    "ACCESS_KEY = \"\"\n",
    "\n",
    "connection = ArthurAI(url=URL, access_key=ACCESS_KEY, client_version=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = connection.model(partner_model_id=\"MEPS_drift_1\",\n",
    "#                          input_type=InputType.Tabular,\n",
    "#                          output_type=OutputType.Multiclass,\n",
    "#                          is_batch=True)\n",
    "\n",
    "model = connection.get_model('MEPS_drift_1', id_type='partner_model_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up ArthurModel\n",
    "Everything under this header is *necessary* for an `ArthurModel` to be created; additional functionality is not \n",
    "possible until after `model.save()` has been successfully called.\n",
    "\n",
    "*Some context about this dataset:*\n",
    "\n",
    "- label: `UTILIZATION`, where 1: >10 visits, 0: <10 visits\n",
    "\n",
    "- protected attribute: `RACE`, where 1: `White`, 0: `Non-White`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_data_full contains the X's and the Y's\n",
    "all_data = pd.read_parquet('fulldata_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['p_0', 'p_1', 'gt']"
      ],
      "text/plain": [
       "['p_0', 'p_1', 'gt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns.tolist()[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the attributes used for training to the model and set them to ModelPipelineInput\n",
    "# note that attribute names need to contain only letters, numbers, and underscores, and cannot begin with a number\n",
    "train_x = all_data.drop(columns=['RACE','p_0', 'p_1', 'gt'])\n",
    "model.from_dataframe(train_x, Stage.ModelPipelineInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bias monitoring - this cannot be done after the model is saved\n",
    "# to monitor for bias, 'RACE' must be an int (or take on discrete string values)\n",
    "all_data['RACE'] = all_data['RACE'].astype(int)\n",
    "sens_x = pd.DataFrame(data={'RACE': all_data['RACE']})\n",
    "model.from_dataframe(sens_x, Stage.NonInputData)\n",
    "\n",
    "model.get_attribute('RACE', stage=Stage.NonInputData).monitor_for_bias=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_high_utilization': <arthurai.client.apiv3.attributes.ArthurAttribute at 0x7f87b9d88040>,\n",
       " 'gt_high_utilization': <arthurai.client.apiv3.attributes.ArthurAttribute at 0x7f87b9d455b0>,\n",
       " 'pred_low_utilization': <arthurai.client.apiv3.attributes.ArthurAttribute at 0x7f87c411a190>,\n",
       " 'gt_low_utilization': <arthurai.client.apiv3.attributes.ArthurAttribute at 0x7f87b9d98820>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gt_<>_utilization will refer to the ground truth values (i.e. true labels), while\n",
    "# pred_<>_utilization will refer to the predicted outputs of your model. \n",
    "pred_to_ground_truth_map = {\n",
    "    \"pred_high_utilization\": \"gt_high_utilization\",\n",
    "    \"pred_low_utilization\": \"gt_low_utilization\"\n",
    "}\n",
    "\n",
    "# add the ground truth and predicted attributes to the model\n",
    "model.add_binary_classifier_output_attributes('pred_high_utilization', pred_to_ground_truth_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>stage</th>\n",
       "      <th>value_type</th>\n",
       "      <th>categorical</th>\n",
       "      <th>is_unique</th>\n",
       "      <th>categories</th>\n",
       "      <th>range</th>\n",
       "      <th>monitor_for_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gt_low_utilization</td>\n",
       "      <td>GROUND_TRUTH</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 0}, {value: 1}]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gt_high_utilization</td>\n",
       "      <td>GROUND_TRUTH</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 0}, {value: 1}]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RACE</td>\n",
       "      <td>NON_INPUT_DATA</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 0}, {value: 1}]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PHQ24201</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEX2</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>OHRTDX2</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>PREGNT01</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>RTHLTH5</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>pred_low_utilization</td>\n",
       "      <td>PREDICTED_VALUE</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>pred_high_utilization</td>\n",
       "      <td>PREDICTED_VALUE</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name            stage value_type categorical is_unique  \\\n",
       "0       gt_low_utilization     GROUND_TRUTH    INTEGER        True     False   \n",
       "1      gt_high_utilization     GROUND_TRUTH    INTEGER        True     False   \n",
       "2                     RACE   NON_INPUT_DATA    INTEGER        True     False   \n",
       "3                 PHQ24201   PIPELINE_INPUT      FLOAT       False     False   \n",
       "4                     SEX2   PIPELINE_INPUT      FLOAT       False     False   \n",
       "..                     ...              ...        ...         ...       ...   \n",
       "137                OHRTDX2   PIPELINE_INPUT      FLOAT       False     False   \n",
       "138               PREGNT01   PIPELINE_INPUT      FLOAT       False     False   \n",
       "139                RTHLTH5   PIPELINE_INPUT      FLOAT       False     False   \n",
       "140   pred_low_utilization  PREDICTED_VALUE      FLOAT       False     False   \n",
       "141  pred_high_utilization  PREDICTED_VALUE      FLOAT       False     False   \n",
       "\n",
       "                   categories         range monitor_for_bias  \n",
       "0    [{value: 0}, {value: 1}]  [None, None]            False  \n",
       "1    [{value: 0}, {value: 1}]  [None, None]            False  \n",
       "2    [{value: 0}, {value: 1}]  [None, None]             True  \n",
       "3                          []    [0.0, 1.0]            False  \n",
       "4                          []    [0.0, 1.0]            False  \n",
       "..                        ...           ...              ...  \n",
       "137                        []    [0.0, 1.0]            False  \n",
       "138                        []    [0.0, 1.0]            False  \n",
       "139                        []    [0.0, 1.0]            False  \n",
       "140                        []        [0, 1]            False  \n",
       "141                        []        [0, 1]            False  \n",
       "\n",
       "[142 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check all the attributes loaded to the model. note that even though you passed in your \"real\" training\n",
    "# data, currently the model has no reference to the actual datapoints -- just the properties of the \n",
    "# attributes. you will need to set reference data (for data drift detection) later\n",
    "model.review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "An error occurred: {'error': 'cannot update model due to invalid attributes: attribute names must be unique for a specific model, AGE is defined more then once'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7758743b9848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# your model is not uploaded to Arthur until you call model.save()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model.save()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/c/Users/jessica/Documents/github/arthur/arthur-ai-sdk/python/arthurai/client/apiv3/models.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m                                 return_raw_response=True)\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"An error occurred: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_response_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: An error occurred: {'error': 'cannot update model due to invalid attributes: attribute names must be unique for a specific model, AGE is defined more then once'}"
     ]
    }
   ],
   "source": [
    "# your model is not uploaded to Arthur until you call model.save()\n",
    "# model.save()\n",
    "# model.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding additional functionality\n",
    "\n",
    "Setting reference data and monitoring for bias adds to the functionality of the `ArthurModel` that you've created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting reference data\n",
    "\n",
    "Now that we've saved the model, we can set reference data.\n",
    "The reference data df must have a column for each `ModelPipelineInput` and each `NonInput`. Optionally, it \n",
    "can contain predicted value and ground truth columns; this will enable the calculation of data drift \n",
    "on output attributes. In this model, our ground truth columns are `gt_high_utilization` and `gt_low_utilization`,\n",
    "and our predicted value columns are `pred_high_utilization` and `pred_low_utilization`. \n",
    "\n",
    "We need to rename and update the columns in `all_data` to match these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['p_0', 'p_1', 'gt']\n",
    "all_data = all_data.rename(columns={'p_0': 'pred_low_utilization', 'p_1': 'pred_high_utilization'})\n",
    "gt = pd.get_dummies(all_data['gt'], prefix='gt', dtype='int')\n",
    "gt = gt.rename(columns={'gt_0.0': 'gt_low_utilization', 'gt_1.0': 'gt_high_utilization'})\n",
    "all_data = all_data.drop(columns=['gt'])\n",
    "all_data = all_data.merge(gt, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE                      float64\n",
       "RACE                       int64\n",
       "PCS42                    float64\n",
       "MCS42                    float64\n",
       "K6SUM42                  float64\n",
       "                          ...   \n",
       "INSCOV3                  float64\n",
       "pred_low_utilization     float64\n",
       "pred_high_utilization    float64\n",
       "gt_low_utilization         int64\n",
       "gt_high_utilization        int64\n",
       "Length: 142, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'counts': {'success': 161, 'failure': 0, 'total': 161}, 'failures': [[]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_reference_data(data=all_data) # note: need to explicitly specify the data= argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting bias monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### send batches of inferences\n",
    "\n",
    "We do not need to load/expose the actual predictive model to send inferences to `arthur_model`. `x_shift` is a directory holding batched data. Each of the parquet files is a dataframe with the following columns:\n",
    "\n",
    "- sensitive attribute, `RACE`\n",
    "- all attributes used for training\n",
    "- `p_0`: the predicted probability of this example being in the 0 class - *given by your model*\n",
    "- `p_1`: the predicted probability of this example being in the 1 class - *given by your model*\n",
    "- `gt`: the ground truth label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mfulldata_0.parquet\u001b[0m*  \u001b[01;32mfulldata_3.parquet\u001b[0m*  \u001b[01;32mfulldata_6.parquet\u001b[0m*\r\n",
      "\u001b[01;32mfulldata_1.parquet\u001b[0m*  \u001b[01;32mfulldata_4.parquet\u001b[0m*  \u001b[01;32mfulldata_7.parquet\u001b[0m*\r\n",
      "\u001b[01;32mfulldata_2.parquet\u001b[0m*  \u001b[01;32mfulldata_5.parquet\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls x_shift "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### batch inference format\n",
    "(df option)\n",
    "Your batch inferences must have the dummied prediction columns that you created earlier; \n",
    "if you don't have ground truth labels at this time, you don't need to send them now.\n",
    "When sending batch inferences, you must add the following additional columns: \n",
    "- `batch_id` - string\n",
    "- `partner_inference_id`- string\n",
    "- `inference_timestamp` - datetime.datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 804\r\n",
      "-rwxrwxrwx 1 jessica jessica 101767 Sep 29 13:15 \u001b[0m\u001b[01;32mfulldata_0.parquet\u001b[0m*\r\n",
      "-rwxrwxrwx 1 jessica jessica 101252 Sep 29 13:15 \u001b[01;32mfulldata_1.parquet\u001b[0m*\r\n",
      "-rwxrwxrwx 1 jessica jessica 100909 Sep 29 13:15 \u001b[01;32mfulldata_2.parquet\u001b[0m*\r\n",
      "-rwxrwxrwx 1 jessica jessica 100660 Sep 29 13:15 \u001b[01;32mfulldata_3.parquet\u001b[0m*\r\n",
      "-rwxrwxrwx 1 jessica jessica 101455 Sep 29 13:15 \u001b[01;32mfulldata_4.parquet\u001b[0m*\r\n",
      "-rwxrwxrwx 1 jessica jessica 102370 Sep 29 13:15 \u001b[01;32mfulldata_5.parquet\u001b[0m*\r\n",
      "-rwxrwxrwx 1 jessica jessica 102213 Sep 29 13:15 \u001b[01;32mfulldata_6.parquet\u001b[0m*\r\n",
      "-rwxrwxrwx 1 jessica jessica 102689 Sep 29 13:15 \u001b[01;32mfulldata_7.parquet\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls -l x_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4): # sending inferences without ground truth\n",
    "    alldata = pd.read_parquet('x_shift/fulldata_'+str(i) +'.parquet')\n",
    "    tosend = alldata.rename(columns={'p_0': 'pred_low_utilization', 'p_1': 'pred_high_utilization'})\n",
    "    tosend['RACE'] = tosend['RACE'].astype(int)\n",
    "    \n",
    "    tosend['batch_id'] = [str(i)]*len(tosend)\n",
    "    tosend['partner_inference_id'] = [str(np.random.randint(10000))]*len(tosend)\n",
    "    tosend['inference_timestamp'] = [(datetime.now())]*len(tosend)\n",
    "    \n",
    "    model.send_batch_inferences(data=tosend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4): # adding ground truth later\n",
    "    alldata = pd.read_parquet('x_shift/fulldata_'+str(i) +'.parquet')\n",
    "    tosend = pd.get_dummies(alldata['gt'], prefix='gt')\n",
    "    tosend = tosend.rename(columns={'gt_0.0': 'gt_low_utilization', 'gt_1.0': 'gt_high_utilization'})\n",
    "\n",
    "    tosend['batch_id'] = [str(i)]*len(tosend)\n",
    "    tosend['partner_inference_id'] = [str(np.random.randint(10000))]*len(tosend)\n",
    "    tosend['inference_timestamp'] = [(datetime.now())]*len(tosend)\n",
    "    \n",
    "    model.send_batch_inferences(data=tosend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4): # adding gt and infs at the same time\n",
    "    alldata = pd.read_parquet('x_shift/fulldata_'+str(i+4) +'.parquet')\n",
    "    tosend = alldata.rename(columns={'p_0': 'pred_low_utilization', 'p_1': 'pred_high_utilization'})\n",
    "    tosend['RACE'] = tosend['RACE'].astype(int)\n",
    "    \n",
    "    gts = pd.get_dummies(alldata['gt'], prefix='gt')\n",
    "    gts = gts.rename(columns={'gt_0.0': 'gt_low_utilization', 'gt_1.0': 'gt_high_utilization'})\n",
    "    \n",
    "    tosend = tosend.merge(gts, left_index=True, right_index=True)\n",
    "\n",
    "    tosend['batch_id'] = [str(i+4)]*len(tosend)\n",
    "    tosend['partner_inference_id'] = [str(np.random.randint(10000))]*len(tosend)\n",
    "    tosend['inference_timestamp'] = [(datetime.now())]*len(tosend)\n",
    "    \n",
    "    model.send_batch_inferences(data=tosend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>RACE</th>\n",
       "      <th>PCS42</th>\n",
       "      <th>MCS42</th>\n",
       "      <th>K6SUM42</th>\n",
       "      <th>REGION=1</th>\n",
       "      <th>REGION=2</th>\n",
       "      <th>REGION=3</th>\n",
       "      <th>REGION=4</th>\n",
       "      <th>SEX=1</th>\n",
       "      <th>...</th>\n",
       "      <th>INSCOV=2</th>\n",
       "      <th>INSCOV=3</th>\n",
       "      <th>gt</th>\n",
       "      <th>pred_low_utilization</th>\n",
       "      <th>pred_high_utilization</th>\n",
       "      <th>gt_low_utilization</th>\n",
       "      <th>gt_high_utilization</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>partner_inference_id</th>\n",
       "      <th>inference_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.869469</td>\n",
       "      <td>40.166361</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952468</td>\n",
       "      <td>0.047532</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2158</td>\n",
       "      <td>2020-09-29 13:42:38.131723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.196581</td>\n",
       "      <td>-3.431802</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953807</td>\n",
       "      <td>0.046193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2158</td>\n",
       "      <td>2020-09-29 13:42:38.131723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.969287</td>\n",
       "      <td>52.027320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.861396</td>\n",
       "      <td>0.138604</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2158</td>\n",
       "      <td>2020-09-29 13:42:38.131723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.512119</td>\n",
       "      <td>56.755231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965449</td>\n",
       "      <td>0.034551</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2158</td>\n",
       "      <td>2020-09-29 13:42:38.131723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.340100</td>\n",
       "      <td>-1.430711</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.793208</td>\n",
       "      <td>0.206792</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2158</td>\n",
       "      <td>2020-09-29 13:42:38.131723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AGE  RACE      PCS42      MCS42  K6SUM42  REGION=1  REGION=2  REGION=3  \\\n",
       "0  46.0     0  65.869469  40.166361      2.0       1.0       0.0       0.0   \n",
       "1  11.0     0   5.196581  -3.431802     -1.0       1.0       0.0       0.0   \n",
       "2  58.0     0  57.969287  52.027320      0.0       0.0       0.0       1.0   \n",
       "3  24.0     0  64.512119  56.755231      0.0       1.0       0.0       0.0   \n",
       "4   5.0     1   5.340100  -1.430711     -1.0       0.0       1.0       0.0   \n",
       "\n",
       "   REGION=4  SEX=1  ...  INSCOV=2  INSCOV=3   gt  pred_low_utilization  \\\n",
       "0       0.0    0.0  ...       1.0       0.0  0.0              0.952468   \n",
       "1       0.0    0.0  ...       0.0       0.0  0.0              0.953807   \n",
       "2       0.0    1.0  ...       1.0       0.0  0.0              0.861396   \n",
       "3       0.0    1.0  ...       0.0       1.0  0.0              0.965449   \n",
       "4       0.0    0.0  ...       0.0       0.0  0.0              0.793208   \n",
       "\n",
       "   pred_high_utilization  gt_low_utilization  gt_high_utilization  batch_id  \\\n",
       "0               0.047532                   1                    0         7   \n",
       "1               0.046193                   1                    0         7   \n",
       "2               0.138604                   1                    0         7   \n",
       "3               0.034551                   1                    0         7   \n",
       "4               0.206792                   1                    0         7   \n",
       "\n",
       "   partner_inference_id        inference_timestamp  \n",
       "0                  2158 2020-09-29 13:42:38.131723  \n",
       "1                  2158 2020-09-29 13:42:38.131723  \n",
       "2                  2158 2020-09-29 13:42:38.131723  \n",
       "3                  2158 2020-09-29 13:42:38.131723  \n",
       "4                  2158 2020-09-29 13:42:38.131723  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tosend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e674527e-4402-4c2a-9513-f06b579d49b1'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/jessica/Documents/github/arthur/demo_client/notebooks/healthcare_shift'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
