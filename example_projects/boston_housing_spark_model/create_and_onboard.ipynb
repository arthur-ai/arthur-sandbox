{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('app').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SparkML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- crim: double (nullable = true)\n",
      " |-- zn: double (nullable = true)\n",
      " |-- indus: double (nullable = true)\n",
      " |-- chas: integer (nullable = true)\n",
      " |-- nox: double (nullable = true)\n",
      " |-- rm: double (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- dis: double (nullable = true)\n",
      " |-- rad: integer (nullable = true)\n",
      " |-- tax: integer (nullable = true)\n",
      " |-- ptratio: double (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- lstat: double (nullable = true)\n",
      " |-- medv: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = spark.read.csv('./data/boston_housing.csv', header=True, inferSchema=True)\n",
    "data.printSchema()\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_columns = data.columns[:-1] # here we omit the final column\n",
    "assembler = VectorAssembler(inputCols=feature_columns,outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "algo = LinearRegression(featuresCol=\"features\", labelCol=\"medv\", maxIter=10, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Save Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        prediction|\n",
      "+------------------+\n",
      "|30.481707803483047|\n",
      "| 16.89827799730775|\n",
      "|40.212911231135195|\n",
      "| 33.97810421299857|\n",
      "|  31.0127510212452|\n",
      "|29.605011549181675|\n",
      "| 29.89424834671887|\n",
      "|20.987956345840807|\n",
      "|27.596850682188567|\n",
      "| 36.79490216562817|\n",
      "|22.783675426549465|\n",
      "|36.401465521459905|\n",
      "|22.124403711703017|\n",
      "|27.751813493172925|\n",
      "|17.306536637397006|\n",
      "| 24.27501240378283|\n",
      "|30.074080207076484|\n",
      "|25.999155030858645|\n",
      "|31.640696850526474|\n",
      "|26.691771062721898|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[assembler, algo]) \n",
    "\n",
    "fitted_pipeline = pipeline.fit(train)\n",
    "\n",
    "fitted_pipeline.transform(test).select('prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_pipeline.write().overwrite().save('./data/models/boton_housing_spark_model_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        prediction|\n",
      "+------------------+\n",
      "|30.481707803483047|\n",
      "| 16.89827799730775|\n",
      "|40.212911231135195|\n",
      "| 33.97810421299857|\n",
      "|  31.0127510212452|\n",
      "|29.605011549181675|\n",
      "| 29.89424834671887|\n",
      "|20.987956345840807|\n",
      "|27.596850682188567|\n",
      "| 36.79490216562817|\n",
      "|22.783675426549465|\n",
      "|36.401465521459905|\n",
      "|22.124403711703017|\n",
      "|27.751813493172925|\n",
      "|17.306536637397006|\n",
      "| 24.27501240378283|\n",
      "|30.074080207076484|\n",
      "|25.999155030858645|\n",
      "|31.640696850526474|\n",
      "|26.691771062721898|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "loaded_model_pipeline = PipelineModel.load(\"./data/models/boton_housing_spark_model_pipeline\")\n",
    "\n",
    "loaded_model_pipeline.transform(test).select('prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On-board to Arthur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arthurai import ArthurAI\n",
    "from arthurai import ModelType, InputType, Stage, DataType, ArthurModel\n",
    "from arthurai.client.apiv2.arthur_explainer import ArthurExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ArthurAI(url='dashboard.arthur.ai', access_key='<access_key>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00906</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>7.088</td>\n",
       "      <td>20.8</td>\n",
       "      <td>7.3073</td>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "      <td>15.3</td>\n",
       "      <td>394.72</td>\n",
       "      <td>7.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01096</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.389</td>\n",
       "      <td>6.453</td>\n",
       "      <td>31.9</td>\n",
       "      <td>7.3073</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>15.3</td>\n",
       "      <td>394.72</td>\n",
       "      <td>8.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01301</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.442</td>\n",
       "      <td>7.241</td>\n",
       "      <td>49.3</td>\n",
       "      <td>7.0379</td>\n",
       "      <td>1</td>\n",
       "      <td>284</td>\n",
       "      <td>15.5</td>\n",
       "      <td>394.74</td>\n",
       "      <td>5.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01311</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>7.249</td>\n",
       "      <td>21.9</td>\n",
       "      <td>8.6966</td>\n",
       "      <td>5</td>\n",
       "      <td>226</td>\n",
       "      <td>17.9</td>\n",
       "      <td>395.93</td>\n",
       "      <td>4.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01381</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.422</td>\n",
       "      <td>7.875</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.6484</td>\n",
       "      <td>4</td>\n",
       "      <td>255</td>\n",
       "      <td>14.4</td>\n",
       "      <td>394.23</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00906  90.0   2.97     0  0.400  7.088  20.8  7.3073    1  285     15.3   \n",
       "1  0.01096  55.0   2.25     0  0.389  6.453  31.9  7.3073    1  300     15.3   \n",
       "2  0.01301  35.0   1.52     0  0.442  7.241  49.3  7.0379    1  284     15.5   \n",
       "3  0.01311  90.0   1.22     0  0.403  7.249  21.9  8.6966    5  226     17.9   \n",
       "4  0.01381  80.0   0.46     0  0.422  7.875  32.0  5.6484    4  255     14.4   \n",
       "\n",
       "        b  lstat  \n",
       "0  394.72   7.85  \n",
       "1  394.72   8.23  \n",
       "2  394.74   5.49  \n",
       "3  395.93   4.81  \n",
       "4  394.23   2.97  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe from the training data to on-board model metadata\n",
    "train_df = train.toPandas()\n",
    "train_df = train_df.drop('medv', axis=1)  # drop predicted value column to leave only pipeline input\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_METADATA = {\n",
    "    \"name\": 'Spark Boston Housing Model',\n",
    "    \"description\": \"Spark Boston Housing Model\",\n",
    "    \"input_type\": InputType.Tabular,\n",
    "    \"model_type\": ModelType.Regression,\n",
    "    \"tags\": ['Spark'],\n",
    "    \"is_batch\": True\n",
    "}\n",
    "\n",
    "model = client.model(**MODEL_METADATA)\n",
    "model.from_dataframe(train_df[list(train_df.columns)[0:]], Stage.ModelPipelineInput)\n",
    "model.attribute(\n",
    "    name='medv',\n",
    "    stage=Stage.GroundTruth,\n",
    "    data_type=DataType.Float,\n",
    "    categorical=False,\n",
    "    position=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name               stage                     data_type         categorical  is_unique  \n",
      "crim               Stage.ModelPipelineInput  DataType.Float    False        True       \n",
      "zn                 Stage.ModelPipelineInput  DataType.Float    False        True       \n",
      "indus              Stage.ModelPipelineInput  DataType.Float    False        True       \n",
      "chas               Stage.ModelPipelineInput  DataType.Integer  True         False      \n",
      "nox                Stage.ModelPipelineInput  DataType.Float    False        True       \n",
      "rm                 Stage.ModelPipelineInput  DataType.Float    False        True       \n",
      "age                Stage.ModelPipelineInput  DataType.Float    False        True       \n",
      "dis                Stage.ModelPipelineInput  DataType.Float    False        True       \n",
      "rad                Stage.ModelPipelineInput  DataType.Integer  True         False      \n",
      "tax                Stage.ModelPipelineInput  DataType.Integer  False        True       \n",
      "ptratio            Stage.ModelPipelineInput  DataType.Float    False        True       \n",
      "b                  Stage.ModelPipelineInput  DataType.Float    False        True       \n",
      "lstat              Stage.ModelPipelineInput  DataType.Float    False        True       \n",
      "medv               Stage.PredictedValue      DataType.Float    False        False      \n",
      "medv_ground_truth  Stage.GroundTruth         DataType.Float    False        False      \n"
     ]
    }
   ],
   "source": [
    "# review the model to ensure all attributes were inferred correctly\n",
    "model.review_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 24]\n"
     ]
    }
   ],
   "source": [
    "# chas and rad are categorical, check the inferred possible categories\n",
    "print(model.get_attribute('chas', Stage.ModelPipelineInput).categories)\n",
    "print(model.get_attribute('rad', Stage.ModelPipelineInput).categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using a spark model be sure to allocate at least 2 cpus to the model server.\n",
    "# This can scale as you change the configurations of the spark session in your entrypoint\n",
    "# script.\n",
    "model.enable_explainability(df=train_df, project_directory='.',\n",
    "                            user_predict_function_import_path='entrypoint',\n",
    "                            requirements_file='requirements.txt',\n",
    "                            model_server_num_cpu='2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b4f289a5-37cc-4514-a0c5-2e16d22bd987'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send an inference batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+------+-----+----+-------+---+---+-------+------+-----+-----------------+\n",
      "|   crim|  zn|indus|chas|   nox|   rm| age|    dis|rad|tax|ptratio|     b|lstat|medv_ground_truth|\n",
      "+-------+----+-----+----+------+-----+----+-------+---+---+-------+------+-----+-----------------+\n",
      "|0.00632|18.0| 2.31|   0| 0.538|6.575|65.2|   4.09|  1|296|   15.3| 396.9| 4.98|             24.0|\n",
      "| 0.0136|75.0|  4.0|   0|  0.41|5.888|47.6| 7.3197|  3|469|   21.1| 396.9| 14.8|             18.9|\n",
      "|0.01501|90.0| 1.21|   1| 0.401|7.923|24.8|  5.885|  1|198|   13.6|395.52| 3.16|             50.0|\n",
      "|0.01538|90.0| 3.75|   0| 0.394|7.454|34.2| 6.3361|  3|244|   15.9|386.34| 3.11|             44.0|\n",
      "|0.02729| 0.0| 7.07|   0| 0.469|7.185|61.1| 4.9671|  2|242|   17.8|392.83| 4.03|             34.7|\n",
      "| 0.0315|95.0| 1.47|   0| 0.403|6.975|15.3| 7.6534|  3|402|   17.0| 396.9| 4.56|             34.9|\n",
      "|0.03237| 0.0| 2.18|   0| 0.458|6.998|45.8| 6.0622|  3|222|   18.7|394.63| 2.94|             33.4|\n",
      "|0.03427| 0.0| 5.19|   0| 0.515|5.869|46.3| 5.2311|  5|224|   20.2| 396.9|  9.8|             19.5|\n",
      "|0.03445|82.5| 2.03|   0| 0.415|6.162|38.4|   6.27|  2|348|   14.7|393.77| 7.43|             24.1|\n",
      "| 0.0351|95.0| 2.68|   0|0.4161|7.853|33.2|  5.118|  4|224|   14.7|392.78| 3.81|             48.5|\n",
      "|0.03548|80.0| 3.64|   0| 0.392|5.876|19.1| 9.2203|  1|315|   16.4|395.18| 9.25|             20.9|\n",
      "|0.03578|20.0| 3.33|   0|0.4429| 7.82|64.5| 4.6947|  5|216|   14.9|387.31| 3.76|             45.4|\n",
      "|0.03961| 0.0| 5.19|   0| 0.515|6.037|34.5| 5.9853|  5|224|   20.2| 396.9| 8.01|             21.1|\n",
      "|0.04113|25.0| 4.86|   0| 0.426|6.727|33.5| 5.4007|  4|281|   19.0| 396.9| 5.29|             28.0|\n",
      "|0.04301|80.0| 1.91|   0| 0.413|5.663|21.9|10.5857|  4|334|   22.0| 382.8| 8.05|             18.2|\n",
      "|0.04337|21.0| 5.64|   0| 0.439|6.115|63.0| 6.8147|  4|243|   16.8|393.97| 9.43|             20.5|\n",
      "|0.04417|70.0| 2.24|   0|   0.4|6.871|47.4| 7.8278|  5|358|   14.8|390.86| 6.07|             24.8|\n",
      "| 0.0459|52.5| 5.32|   0| 0.405|6.315|45.6| 7.3172|  6|293|   16.6| 396.9|  7.6|             22.3|\n",
      "|0.04666|80.0| 1.52|   0| 0.404|7.107|36.6|  7.309|  2|329|   12.6|354.31| 8.61|             30.3|\n",
      "|0.04684| 0.0| 3.41|   0| 0.489|6.417|66.1| 3.0923|  2|270|   17.8|392.18| 8.81|             22.6|\n",
      "+-------+----+-----+----+------+-----+----+-------+---+---+-------+------+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ground truth must be sent separately when sending batch data, lets create a ground truth column to later break out\n",
    "# and upload. Also note the convention that the ground truth column must be names the same as its \n",
    "# corresponding predicted value attribute with \"_ground_truth\" appended\n",
    "test = test.withColumnRenamed(\"medv\",\"medv_ground_truth\")\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+------+-----+----+-------+---+---+-------+------+-----+-----------------+--------------------+------------------+--------------------+\n",
      "|   crim|  zn|indus|chas|   nox|   rm| age|    dis|rad|tax|ptratio|     b|lstat|medv_ground_truth|            features|              medv|         external_id|\n",
      "+-------+----+-----+----+------+-----+----+-------+---+---+-------+------+-----+-----------------+--------------------+------------------+--------------------+\n",
      "|0.00632|18.0| 2.31|   0| 0.538|6.575|65.2|   4.09|  1|296|   15.3| 396.9| 4.98|             24.0|[0.00632,18.0,2.3...|30.481707803483047|d545f0ca-73ae-456...|\n",
      "| 0.0136|75.0|  4.0|   0|  0.41|5.888|47.6| 7.3197|  3|469|   21.1| 396.9| 14.8|             18.9|[0.0136,75.0,4.0,...| 16.89827799730775|0ce4fdf0-6b77-4b4...|\n",
      "|0.01501|90.0| 1.21|   1| 0.401|7.923|24.8|  5.885|  1|198|   13.6|395.52| 3.16|             50.0|[0.01501,90.0,1.2...|40.212911231135195|c13c119e-8752-46b...|\n",
      "|0.01538|90.0| 3.75|   0| 0.394|7.454|34.2| 6.3361|  3|244|   15.9|386.34| 3.11|             44.0|[0.01538,90.0,3.7...| 33.97810421299857|93bb1307-ce9c-4fb...|\n",
      "|0.02729| 0.0| 7.07|   0| 0.469|7.185|61.1| 4.9671|  2|242|   17.8|392.83| 4.03|             34.7|[0.02729,0.0,7.07...|  31.0127510212452|bc3ac661-22ec-43e...|\n",
      "| 0.0315|95.0| 1.47|   0| 0.403|6.975|15.3| 7.6534|  3|402|   17.0| 396.9| 4.56|             34.9|[0.0315,95.0,1.47...|29.605011549181675|8a163a99-1205-46c...|\n",
      "|0.03237| 0.0| 2.18|   0| 0.458|6.998|45.8| 6.0622|  3|222|   18.7|394.63| 2.94|             33.4|[0.03237,0.0,2.18...| 29.89424834671887|198867df-b004-493...|\n",
      "|0.03427| 0.0| 5.19|   0| 0.515|5.869|46.3| 5.2311|  5|224|   20.2| 396.9|  9.8|             19.5|[0.03427,0.0,5.19...|20.987956345840807|62f3c272-44b5-404...|\n",
      "|0.03445|82.5| 2.03|   0| 0.415|6.162|38.4|   6.27|  2|348|   14.7|393.77| 7.43|             24.1|[0.03445,82.5,2.0...|27.596850682188567|87720c83-b43b-4b2...|\n",
      "| 0.0351|95.0| 2.68|   0|0.4161|7.853|33.2|  5.118|  4|224|   14.7|392.78| 3.81|             48.5|[0.0351,95.0,2.68...| 36.79490216562817|3472bf2d-e1bc-458...|\n",
      "|0.03548|80.0| 3.64|   0| 0.392|5.876|19.1| 9.2203|  1|315|   16.4|395.18| 9.25|             20.9|[0.03548,80.0,3.6...|22.783675426549465|e5bac390-e5e1-450...|\n",
      "|0.03578|20.0| 3.33|   0|0.4429| 7.82|64.5| 4.6947|  5|216|   14.9|387.31| 3.76|             45.4|[0.03578,20.0,3.3...|36.401465521459905|5b2f5069-bdc5-45e...|\n",
      "|0.03961| 0.0| 5.19|   0| 0.515|6.037|34.5| 5.9853|  5|224|   20.2| 396.9| 8.01|             21.1|[0.03961,0.0,5.19...|22.124403711703017|8f3e3a9e-4a01-4dc...|\n",
      "|0.04113|25.0| 4.86|   0| 0.426|6.727|33.5| 5.4007|  4|281|   19.0| 396.9| 5.29|             28.0|[0.04113,25.0,4.8...|27.751813493172925|f2cef47a-237b-46d...|\n",
      "|0.04301|80.0| 1.91|   0| 0.413|5.663|21.9|10.5857|  4|334|   22.0| 382.8| 8.05|             18.2|[0.04301,80.0,1.9...|17.306536637397006|17c4a4b4-bd4f-4b8...|\n",
      "|0.04337|21.0| 5.64|   0| 0.439|6.115|63.0| 6.8147|  4|243|   16.8|393.97| 9.43|             20.5|[0.04337,21.0,5.6...| 24.27501240378283|5ccabd9c-05e1-436...|\n",
      "|0.04417|70.0| 2.24|   0|   0.4|6.871|47.4| 7.8278|  5|358|   14.8|390.86| 6.07|             24.8|[0.04417,70.0,2.2...|30.074080207076484|b01e817b-11c5-40a...|\n",
      "| 0.0459|52.5| 5.32|   0| 0.405|6.315|45.6| 7.3172|  6|293|   16.6| 396.9|  7.6|             22.3|[0.0459,52.5,5.32...|25.999155030858645|b3624efc-e789-446...|\n",
      "|0.04666|80.0| 1.52|   0| 0.404|7.107|36.6|  7.309|  2|329|   12.6|354.31| 8.61|             30.3|[0.04666,80.0,1.5...|31.640696850526474|34d836ed-60db-446...|\n",
      "|0.04684| 0.0| 3.41|   0| 0.489|6.417|66.1| 3.0923|  2|270|   17.8|392.18| 8.81|             22.6|[0.04684,0.0,3.41...|26.691771062721898|c7a55e9a-a05d-430...|\n",
      "+-------+----+-----+----+------+-----+----+-------+---+---+-------+------+-----+-----------------+--------------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "# make predictions\n",
    "predicted_dataframe = loaded_model_pipeline.transform(test).withColumnRenamed(\"prediction\", \"medv\")\n",
    "# In order to send ground truth we must use an external id to match up rows in the ground truth dataframe and\n",
    "# inferences dataframe\n",
    "uuidUdf= udf(lambda : str(uuid.uuid4()), StringType())\n",
    "predicted_dataframe = predicted_dataframe.withColumn('external_id', uuidUdf())\n",
    "predicted_dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we separate out the inference input dataframe frame and the ground truth dataframe\n",
    "pipeline_input_attr_names = [attr.as_dict()['name'] \n",
    "                             for attr in model.get_attributes_for_stage(Stage.ModelPipelineInput)]\n",
    "columns_to_select = pipeline_input_attr_names + ['medv', 'external_id']\n",
    "batch_inferences = predicted_dataframe.select(columns_to_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting ground truth batch dataframe\n",
    "columns_to_select = ['medv_ground_truth', 'external_id']\n",
    "ground_truth_batch = predicted_dataframe.select(columns_to_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write inferences dataframe to parquet file\n",
    "batch_inferences.write.parquet(\"./data/batch_inference_files/batch_inferences.parquet\")\n",
    "ground_truth_batch.write.parquet(\"./data/batch_ground_truth_files/ground_truth.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.send_batch_inferences(directory_path='./data/batch_inference_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.send_batch_ground_truth(directory_path='./data/batch_ground_truth_files/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
