{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from arthurai import ArthurAI\n",
    "from arthurai.client.apiv3 import InputType, OutputType, Stage\n",
    "import numpy as np\n",
    "import joblib\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from model_utils import transformations, load_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this guide, we'll use the credit dataset (and a pre-trained model) to onboard a new model to the Arthur platform. We'll walk through registering the model using a sample of the training data. This is an example of a streaming model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up connection\n",
    "Supply your API Key below to autheticate with the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "URL = \"app.arthur.ai\"\n",
    "ACCESS_KEY = \"...\"\n",
    "\n",
    "connection = ArthurAI(url=URL, access_key=ACCESS_KEY, client_version=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll instantiate a model object with a small amount of metadata about the model input and output types. Then, we'll use a sample of the training data to register the full data schema for this Tabular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arthur_model = connection.model(partner_model_id=\"CreditRiskModel_v0.0.1\",\n",
    "                               input_type=InputType.Tabular,\n",
    "                               output_type=OutputType.Multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = load_datasets(\"../fixtures/datasets/credit_card_default.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register what the data schema is for the inputs to the model. Since your model might hundreds or thousands of input features, you can just pass us a pandas DataFrame of your training data, and we'll handle the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arthur_model.from_dataframe(X_train, Stage.ModelPipelineInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register the schema for the outputs of the model: what will a typical prediction look like and what will a typical ground truth look like? What names, shapes, and datatypes should Arthur expect for these objects?\n",
    "\n",
    "Since this is a binary classification model, we'll do this all in one step with the *.add_binary_classifier_output_attributes()* method. All we need to supply is a mapping that establishes:\n",
    "  * names for the model's predictions\n",
    "  * names for the model's ground truth\n",
    "  * the mapping that related these two\n",
    "  \n",
    "Our classifier will be making predictions about class *0* and class *1* and will return a probability score for each class. Therefore, we'll set up a name *prediction_0* and a name *prediction_1*. Additionally, our groundtruth will be either a 0 or 1, but we'll always represent ground truth in the one-hot-endoded form. Therefore, we create two field called *gt_0* and *gt_1*. We link these all up in a dictionary and pass that to the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_to_ground_truth_map = {\n",
    "    \"prediction_0\": \"gt_0\",\n",
    "    \"prediction_1\": \"gt_1\"\n",
    "}\n",
    "\n",
    "arthur_model.add_binary_classifier_output_attributes(\"prediction_1\", prediction_to_ground_truth_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first argument to *.add_binary_classifier_output_attributes()* is the name of the \"positive predicted class\", for purposes of calculating accuracy metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before saving, you can review a model to make sure everything is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arthur_model.review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arthur_model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting baseline data\n",
    "Next, we'll use the training data to set a baseline reference for calcuating data drift. \n",
    "\n",
    "For tracking data drift, you can upload a dataset to serve as the baseline or reference set. Often, this is a sample of your training data for the associated model. Our reference dataset should ideally include examples of\n",
    "  * inputs \n",
    "  * ground truth\n",
    "  * model predictions\n",
    "  \n",
    "for a sample of the training set. This way, Arthur can monitor for drift and stability in all of these aspects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our pre-trained classifier so we can generate predictions\n",
    "sk_model = joblib.load(\"../fixtures/serialized_models/credit_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all input columns\n",
    "reference_set = X_train.copy()\n",
    "\n",
    "# get ground truth labels\n",
    "reference_set[\"gt_1\"] = Y_train\n",
    "reference_set[\"gt_0\"] = 1-Y_train\n",
    "\n",
    "# get model predictions\n",
    "preds = sk_model.predict_proba(X_train)\n",
    "reference_set[\"prediction_1\"] = preds[:, 1]\n",
    "reference_set[\"prediction_0\"] = preds[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arthur_model.set_reference_data(data=reference_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test data and trained model. Let's familiarize ourselves with the data and the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_model.predict_proba(X_train.iloc[0:1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To send inferences, we'll iterate through datapoints in a test set and send telemetry to Arthur. You can send inferences one at a time or in a list. We will combine our model inputs and our model predictions into a dictionary called *inference_data*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_test.shape[0]):\n",
    "    datarecord = X_test.iloc[i:i+1, :]\n",
    "    predicted_probs = sk_model.predict_proba(datarecord)[0]\n",
    "    ground_truth = np.int(Y_test.iloc[i])\n",
    "    external_id = str(np.random.randint(1e9))\n",
    "\n",
    "    inputs = datarecord.to_dict(orient='records')[0]\n",
    "    prediction = {\"prediction_1\":predicted_probs[1], \n",
    "                  \"prediction_0\":predicted_probs[0]}\n",
    "    ground_truth={\"gt_1\": ground_truth, \n",
    "                  \"gt_0\":1-ground_truth}\n",
    "\n",
    "    \n",
    "    arthur_model.send_inferences([{\n",
    "        \"inference_timestamp\" : datetime.datetime.utcnow().isoformat() + \"Z\",\n",
    "        \"partner_inference_id\" : external_id,\n",
    "        \"inference_data\": inputs.update(prediction),\n",
    "        \"ground_truth_data\": ground_truth,\n",
    "        \"ground_truth_timestamp\" : datetime.datetime.utcnow().isoformat() + \"Z\"\n",
    "    }])\n",
    "    \n",
    "    print(\"Sent inference with id {}\".format(external_id))\n",
    "    time.sleep(0.001 * np.random.random())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can send inferences one at a time but you can also send them in small bunches using the *send_infereces()* method. In that case, you would send a list of dictionaries, each of which is similar to above. \n",
    "\n",
    "If you model scoring system is a set up in a batch processor where you run a daily, weekly, or monthly job, then we recommend setting a batch model with Arthur and using the corresponding *send_batch_inferences()* method. An example batch model can be found [here](../../credit_risk_batch/notebooks/Quickstart.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
