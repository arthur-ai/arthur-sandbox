{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from arthurai import ArthurAI\n",
    "from arthurai.common.constants import InputType, OutputType, Stage\n",
    "import numpy as np\n",
    "import joblib\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from model_utils import transformations, load_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this guide, we'll use the credit dataset (and a pre-trained model) to onboard a new model to the Arthur platform. We'll walk through registering the model using a sample of the training data. This is an example of a batch model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up connection\n",
    "Supply your API Key below to autheticate with the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "URL = \"dev-v3.arthur.ai\"\n",
    "ACCESS_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdXRob3JpemVkIjp0cnVlLCJjb250ZXh0cyI6W3siY29udGV4dF9pZCI6ImJmZDEyZTcwLWQwMTgtNDlmMy1hYTY3LTRjYzFmOGRhNWZlNiIsImNvbnRleHRfdHlwZSI6Ik9yZ2FuaXphdGlvbiIsInJvbGUiOiJBZG1pbmlzdHJhdG9yIn1dLCJleHAiOjE2MDk5NjI4ODksInVzZXJfaWQiOiI1NDhlZmMxZi0yODZkLTQ0MDctOWU0YS1hM2NhMjgwMDJkMGEifQ.NfsYkMuzlAI1234UzqyRkSfD9Gorg17oJFwDM3JnwHU\"\n",
    "\n",
    "connection = ArthurAI(url=URL, access_key=ACCESS_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll instantiate a model object with a small amount of metadata about the model input and output types. Then, we'll use a sample of the training data to register the full data schema for this Tabular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arthur_model = connection.model(partner_model_id=\"CreditRisk_BatchDeployment_v0.0.1-Harrison-Test\",\n",
    "                               input_type=InputType.Tabular,\n",
    "                               output_type=OutputType.Multiclass,\n",
    "                               is_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = load_datasets(\"../fixtures/datasets/credit_card_default.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19260    1\n",
       "6871     0\n",
       "1915     0\n",
       "19927    0\n",
       "20055    0\n",
       "Name: default payment next month, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19260</th>\n",
       "      <td>250000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>125721</td>\n",
       "      <td>122209</td>\n",
       "      <td>126129</td>\n",
       "      <td>127847</td>\n",
       "      <td>5900</td>\n",
       "      <td>4500</td>\n",
       "      <td>0</td>\n",
       "      <td>5954</td>\n",
       "      <td>3900</td>\n",
       "      <td>4826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6871</th>\n",
       "      <td>360000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>43000</td>\n",
       "      <td>4650</td>\n",
       "      <td>12132</td>\n",
       "      <td>13953</td>\n",
       "      <td>15008</td>\n",
       "      <td>43065</td>\n",
       "      <td>4650</td>\n",
       "      <td>12132</td>\n",
       "      <td>13953</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>240000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>22081</td>\n",
       "      <td>3428</td>\n",
       "      <td>67</td>\n",
       "      <td>1832</td>\n",
       "      <td>5009</td>\n",
       "      <td>2000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>3332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19927</th>\n",
       "      <td>330000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>24420</td>\n",
       "      <td>1380</td>\n",
       "      <td>0</td>\n",
       "      <td>404</td>\n",
       "      <td>0</td>\n",
       "      <td>24420</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20055</th>\n",
       "      <td>230000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "19260     250000    2          1         2   29      2      2      2      2   \n",
       "6871      360000    1          1         1   58     -1     -1     -1     -1   \n",
       "1915      240000    2          1         2   29      0      0      0     -1   \n",
       "19927     330000    2          2         1   39      1     -1     -1     -1   \n",
       "20055     230000    2          1         1   45     -2     -2     -2     -2   \n",
       "\n",
       "       PAY_5  ...  BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  \\\n",
       "19260      2  ...     125721     122209     126129     127847      5900   \n",
       "6871      -1  ...      43000       4650      12132      13953     15008   \n",
       "1915      -1  ...      22081       3428         67       1832      5009   \n",
       "19927      2  ...          0        404        404      24420      1380   \n",
       "20055     -2  ...          0          0          0        136         0   \n",
       "\n",
       "       PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "19260      4500         0      5954      3900      4826  \n",
       "6871      43065      4650     12132     13953      2200  \n",
       "1915       2000      5000         0      3332         0  \n",
       "19927         0       404         0     24420       480  \n",
       "20055         0         0         0       136      1233  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register what the data schema is for the inputs to the model. Since your model might hundreds or thousands of input features, you can just pass us a pandas DataFrame of your training data, and we'll handle the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arthur_model.from_dataframe(X_train, Stage.ModelPipelineInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register the schema for the outputs of the model: what will a typical prediction look like and what will a typical ground truth look like? What names, shapes, and datatypes should Arthur expect for these objects?\n",
    "\n",
    "Since this is a binary classification model, we'll do this all in one step with the *.add_binary_classifier_output_attributes()* method. All we need to supply is a mapping that establishes:\n",
    "  * names for the model's predictions\n",
    "  * names for the model's ground truth\n",
    "  * the mapping that related these two\n",
    "  \n",
    "Our classifier will be making predictions about class *0* and class *1* and will return a probability score for each class. Therefore, we'll set up a name *prediction_0* and a name *prediction_1*. Additionally, our groundtruth will be either a 0 or 1, but we'll always represent ground truth in the one-hot-endoded form. Therefore, we create two field called *gt_0* and *gt_1*. We link these all up in a dictionary and pass that to the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction_0': ArthurAttribute(name='prediction_0', value_type='FLOAT', stage='PREDICTED_VALUE', id=None, label=None, position=0, categorical=False, min_range=0, max_range=1, monitor_for_bias=False, categories=None, bins=None, is_unique=False, is_positive_predicted_attribute=False, attribute_link='gt_0'),\n",
       " 'gt_0': ArthurAttribute(name='gt_0', value_type='INTEGER', stage='GROUND_TRUTH', id=None, label=None, position=0, categorical=True, min_range=None, max_range=None, monitor_for_bias=False, categories=[AttributeCategory(value='0', label=None), AttributeCategory(value='1', label=None)], bins=None, is_unique=False, is_positive_predicted_attribute=False, attribute_link='prediction_0'),\n",
       " 'prediction_1': ArthurAttribute(name='prediction_1', value_type='FLOAT', stage='PREDICTED_VALUE', id=None, label=None, position=1, categorical=False, min_range=0, max_range=1, monitor_for_bias=False, categories=None, bins=None, is_unique=False, is_positive_predicted_attribute=True, attribute_link='gt_1'),\n",
       " 'gt_1': ArthurAttribute(name='gt_1', value_type='INTEGER', stage='GROUND_TRUTH', id=None, label=None, position=1, categorical=True, min_range=None, max_range=None, monitor_for_bias=False, categories=[AttributeCategory(value='0', label=None), AttributeCategory(value='1', label=None)], bins=None, is_unique=False, is_positive_predicted_attribute=False, attribute_link='prediction_1')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_to_ground_truth_map = {\n",
    "    \"prediction_0\": \"gt_0\",\n",
    "    \"prediction_1\": \"gt_1\"\n",
    "}\n",
    "\n",
    "arthur_model.add_binary_classifier_output_attributes(\"prediction_1\", prediction_to_ground_truth_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first argument to *.add_binary_classifier_output_attributes()* is the name of the \"positive predicted class\", for purposes of calculating accuracy metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before saving, you can review a model to make sure everything is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>stage</th>\n",
       "      <th>value_type</th>\n",
       "      <th>categorical</th>\n",
       "      <th>is_unique</th>\n",
       "      <th>categories</th>\n",
       "      <th>bins</th>\n",
       "      <th>range</th>\n",
       "      <th>monitor_for_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIMIT_BAL</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[10000, 1000000]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEX</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 1}, {value: 2}]</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 0}, {value: 1}, {value: 2}, {value: 3...</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MARRIAGE</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 0}, {value: 1}, {value: 2}, {value: 3}]</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGE</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[21, 79]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PAY_0</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 0}, {value: 1}, {value: 2}, {value: 3...</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PAY_2</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 0}, {value: 1}, {value: 2}, {value: 3...</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PAY_3</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 0}, {value: 1}, {value: 2}, {value: 3...</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PAY_4</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 0}, {value: 2}, {value: 3}, {value: 4...</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PAY_5</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 0}, {value: 2}, {value: 3}, {value: 4...</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PAY_6</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 0}, {value: 2}, {value: 3}, {value: 4...</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BILL_AMT1</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[-165580, 964511]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BILL_AMT2</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[-69777, 983931]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BILL_AMT3</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[-157264, 1664089]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BILL_AMT4</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[-170000, 891586]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BILL_AMT5</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[-61372, 927171]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BILL_AMT6</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[-339603, 961664]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PAY_AMT1</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 873552]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PAY_AMT2</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 1684259]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PAY_AMT3</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 896040]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PAY_AMT4</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 621000]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PAY_AMT5</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 426529]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PAY_AMT6</td>\n",
       "      <td>PIPELINE_INPUT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 528666]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gt_0</td>\n",
       "      <td>GROUND_TRUTH</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 0}, {value: 1}]</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>prediction_0</td>\n",
       "      <td>PREDICTED_VALUE</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gt_1</td>\n",
       "      <td>GROUND_TRUTH</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[{value: 0}, {value: 1}]</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>prediction_1</td>\n",
       "      <td>PREDICTED_VALUE</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name            stage value_type categorical is_unique  \\\n",
       "0      LIMIT_BAL   PIPELINE_INPUT    INTEGER       False     False   \n",
       "1            SEX   PIPELINE_INPUT    INTEGER        True     False   \n",
       "2      EDUCATION   PIPELINE_INPUT    INTEGER        True     False   \n",
       "3       MARRIAGE   PIPELINE_INPUT    INTEGER        True     False   \n",
       "4            AGE   PIPELINE_INPUT    INTEGER       False     False   \n",
       "5          PAY_0   PIPELINE_INPUT    INTEGER        True     False   \n",
       "6          PAY_2   PIPELINE_INPUT    INTEGER        True     False   \n",
       "7          PAY_3   PIPELINE_INPUT    INTEGER        True     False   \n",
       "8          PAY_4   PIPELINE_INPUT    INTEGER        True     False   \n",
       "9          PAY_5   PIPELINE_INPUT    INTEGER        True     False   \n",
       "10         PAY_6   PIPELINE_INPUT    INTEGER        True     False   \n",
       "11     BILL_AMT1   PIPELINE_INPUT    INTEGER       False     False   \n",
       "12     BILL_AMT2   PIPELINE_INPUT    INTEGER       False     False   \n",
       "13     BILL_AMT3   PIPELINE_INPUT    INTEGER       False     False   \n",
       "14     BILL_AMT4   PIPELINE_INPUT    INTEGER       False     False   \n",
       "15     BILL_AMT5   PIPELINE_INPUT    INTEGER       False     False   \n",
       "16     BILL_AMT6   PIPELINE_INPUT    INTEGER       False     False   \n",
       "17      PAY_AMT1   PIPELINE_INPUT    INTEGER       False     False   \n",
       "18      PAY_AMT2   PIPELINE_INPUT    INTEGER       False     False   \n",
       "19      PAY_AMT3   PIPELINE_INPUT    INTEGER       False     False   \n",
       "20      PAY_AMT4   PIPELINE_INPUT    INTEGER       False     False   \n",
       "21      PAY_AMT5   PIPELINE_INPUT    INTEGER       False     False   \n",
       "22      PAY_AMT6   PIPELINE_INPUT    INTEGER       False     False   \n",
       "23          gt_0     GROUND_TRUTH    INTEGER        True     False   \n",
       "24  prediction_0  PREDICTED_VALUE      FLOAT       False     False   \n",
       "25          gt_1     GROUND_TRUTH    INTEGER        True     False   \n",
       "26  prediction_1  PREDICTED_VALUE      FLOAT       False     False   \n",
       "\n",
       "                                           categories  bins  \\\n",
       "0                                                  []  None   \n",
       "1                            [{value: 1}, {value: 2}]  None   \n",
       "2   [{value: 0}, {value: 1}, {value: 2}, {value: 3...  None   \n",
       "3    [{value: 0}, {value: 1}, {value: 2}, {value: 3}]  None   \n",
       "4                                                  []  None   \n",
       "5   [{value: 0}, {value: 1}, {value: 2}, {value: 3...  None   \n",
       "6   [{value: 0}, {value: 1}, {value: 2}, {value: 3...  None   \n",
       "7   [{value: 0}, {value: 1}, {value: 2}, {value: 3...  None   \n",
       "8   [{value: 0}, {value: 2}, {value: 3}, {value: 4...  None   \n",
       "9   [{value: 0}, {value: 2}, {value: 3}, {value: 4...  None   \n",
       "10  [{value: 0}, {value: 2}, {value: 3}, {value: 4...  None   \n",
       "11                                                 []  None   \n",
       "12                                                 []  None   \n",
       "13                                                 []  None   \n",
       "14                                                 []  None   \n",
       "15                                                 []  None   \n",
       "16                                                 []  None   \n",
       "17                                                 []  None   \n",
       "18                                                 []  None   \n",
       "19                                                 []  None   \n",
       "20                                                 []  None   \n",
       "21                                                 []  None   \n",
       "22                                                 []  None   \n",
       "23                           [{value: 0}, {value: 1}]  None   \n",
       "24                                                 []  None   \n",
       "25                           [{value: 0}, {value: 1}]  None   \n",
       "26                                                 []  None   \n",
       "\n",
       "                 range monitor_for_bias  \n",
       "0     [10000, 1000000]            False  \n",
       "1         [None, None]            False  \n",
       "2         [None, None]            False  \n",
       "3         [None, None]            False  \n",
       "4             [21, 79]            False  \n",
       "5         [None, None]            False  \n",
       "6         [None, None]            False  \n",
       "7         [None, None]            False  \n",
       "8         [None, None]            False  \n",
       "9         [None, None]            False  \n",
       "10        [None, None]            False  \n",
       "11   [-165580, 964511]            False  \n",
       "12    [-69777, 983931]            False  \n",
       "13  [-157264, 1664089]            False  \n",
       "14   [-170000, 891586]            False  \n",
       "15    [-61372, 927171]            False  \n",
       "16   [-339603, 961664]            False  \n",
       "17         [0, 873552]            False  \n",
       "18        [0, 1684259]            False  \n",
       "19         [0, 896040]            False  \n",
       "20         [0, 621000]            False  \n",
       "21         [0, 426529]            False  \n",
       "22         [0, 528666]            False  \n",
       "23        [None, None]            False  \n",
       "24              [0, 1]            False  \n",
       "25        [None, None]            False  \n",
       "26              [0, 1]            False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arthur_model.review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6b679915-9882-4027-89a5-36f4399e1484'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arthur_model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting baseline data\n",
    "For tracking data drift, you can upload a dataset to serve as the baseline or reference set. Often, this is a sample of your training data for the associated model. Our reference dataset should ideally include examples of\n",
    "  * inputs \n",
    "  * ground truth\n",
    "  * model predictions\n",
    "  \n",
    "for a sample of the training set. This way, Arthur can monitor for drift and stability in all of these aspects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "Trying to unpickle estimator DecisionTreeClassifier from version 0.21.3 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "Trying to unpickle estimator RandomForestClassifier from version 0.21.3 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "# load our pre-trained classifier so we can generate predictions\n",
    "sk_model = joblib.load(\"../fixtures/serialized_models/credit_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all input columns\n",
    "reference_set = X_train.copy()\n",
    "\n",
    "# get ground truth labels\n",
    "reference_set[\"gt_1\"] = Y_train\n",
    "reference_set[\"gt_0\"] = 1-Y_train\n",
    "\n",
    "# get model predictions\n",
    "preds = sk_model.predict_proba(X_train)\n",
    "reference_set[\"prediction_1\"] = preds[:, 1]\n",
    "reference_set[\"prediction_0\"] = preds[:, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the column names of inputs, predicitons, and ground truths need to match the schema we established at model onboarding. Use *arthur_model.review()* to remind yourself of your naming conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'counts': {'success': 21000, 'failure': 0, 'total': 21000},\n",
       "  'failures': [[]]},\n",
       " {'dataset_close_result': 'success'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arthur_model.set_reference_data(data=reference_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending Batches of Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test data and trained model. Let's familiarize ourselves with the data and the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 23)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(ccp_alpha=None, max_depth=15, n_estimators=500)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1731164, 0.8268836])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_model.predict_proba(X_train.iloc[0:1, :])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple columns in the uploaded dataframe that we should take special note of. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the predictions/scores from your model should match the column names in the registered schema. If we take a look above at *arthur_model.review()* we'll recall that columns we created correspond to the clasiffier's output probabilities over the classes (\"prediction_1\" and \"prediction_0\") and the corresponding ground truth over the possible clases in one-hot form (\"gt_1\" and \"gt_0\").\n",
    "\n",
    "Aside from these model-specific columns, there are some standard inputs need to indentify inferences and batches.\n",
    "* First, each inference needs a unique identifier so that it can later be joined with ground truth. Include a column named **partner_inference_id** and ensure these IDs are unique across batches. For example, if you run predictions across your customer base on a daily-batch cadence, then a unique identfier could be composed of your customer_id plus the date.  \n",
    "* Second, each inference needs to be associated with a **batch_id**, but this id will be shared among one or more inferences. \n",
    "* Finally, each inference needs an **inference_timestamp** and these don't have to be unique.\n",
    "\n",
    "We'll use our clasifier to score a batch of inputs and then assemble those inputs and predictions into a dataframe with the matching column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def make_data_folders(path):\n",
    "    if not os.path.exists(f\"{path}/inferences\"):\n",
    "        os.makedirs(f\"{path}/inferences\")\n",
    "    if not os.path.exists(f\"{path}/ground_truth\"):\n",
    "        os.makedirs(f\"{path}/ground_truth\")\n",
    "\n",
    "num_batches = 1\n",
    "batch_ids = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    batch_size=3000\n",
    "    batch_id = f\"batch_{np.random.randint(1e3)}\"\n",
    "    batch_ids.append(batch_id)\n",
    "    file_loc = f\"../inference_data/{batch_id}\"\n",
    "    make_data_folders(file_loc)\n",
    "\n",
    "    # generate a small batch of rows from the test set, create unique id for each row\n",
    "    rows_inds = np.random.randint(X_test.shape[0], size=batch_size)\n",
    "    batch_inputs_df = X_test.iloc[rows_inds, :]\n",
    "    inference_id = [str(num) for num in np.random.randint(1e11, size=batch_size)]\n",
    "    \n",
    "    # calculate predictions on those rows, fetch ground truth for those rows\n",
    "    batch_predictions = sk_model.predict_proba(batch_inputs_df)\n",
    "    batch_ground_truths = Y_test.values[rows_inds]\n",
    "    \n",
    "    # Next, we put these components together into the dataframe sent to Arthur\n",
    "    # include all input columns to the model\n",
    "    batch_df = batch_inputs_df.copy()\n",
    "    \n",
    "    # need to include model prediction columns, and partner_inference_id\n",
    "    batch_df[\"prediction_0\"] = batch_predictions[:, 0]\n",
    "    batch_df[\"prediction_1\"] = batch_predictions[:, 1]\n",
    "    batch_df[\"partner_inference_id\"] = inference_id\n",
    "    # also need to include a batch_id for the upload, and a timestamp for all the inferences\n",
    "    batch_df[\"inference_timestamp\"]=[(datetime.datetime.utcnow())]*batch_size\n",
    "    # Save batch data to a parquet file\n",
    "    batch_df.to_parquet(f\"{file_loc}/inferences/data.parquet\")\n",
    "    \n",
    "    \n",
    "    # assemble the inference-wise groundtruth and upload\n",
    "    ground_truth_df = pd.DataFrame({\"partner_inference_id\":inference_id,\n",
    "                                   \"gt_0\": 1 - batch_ground_truths ,\n",
    "                                   \"gt_1\": batch_ground_truths,\n",
    "                                   \"ground_truth_timestamp\":[(datetime.datetime.utcnow())]*batch_size})\n",
    "    # Save ground truth data to a parquet file\n",
    "    ground_truth_df.to_parquet(f\"{file_loc}/ground_truth/data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the inference and ground truth data is saved to a parquet file that data can later be retrieved and sent to the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'counts': {'success': 3000, 'failure': 0, 'total': 3000}, 'failures': [[]]}, {'dataset_close_result': 'success'})\n",
      "{'counts': {'success': 3000, 'failure': 0, 'total': 3000}, 'failures': [[]]}\n"
     ]
    }
   ],
   "source": [
    "for batch_id in batch_ids:\n",
    "    file_loc = f\"../inference_data/{batch_id}\"\n",
    "    res = arthur_model.send_batch_inferences(directory_path=f\"{file_loc}/inferences\", batch_id=batch_id)\n",
    "    print(res)\n",
    "    \n",
    "    res = arthur_model.send_batch_ground_truths(directory_path=f\"{file_loc}/ground_truth\")\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending Batches of Ground Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realistically, there will be some delay before you have ground truth for your model's predictions. Whether that ground truth is accessible after one minute or one year, the *send_batch_ground_truths()* method can be called at any later time. The ground truth (labels) will joined with their corresponding predictions to yield accuracy measures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the dataframe here contains similiar required columns such as:\n",
    " * **partner_inference_id**\n",
    " * **batch_id**\n",
    " * **ground_truth_timestamp**\n",
    " \n",
    "And then it also contains columns that are specific to our model and match the ground truth schema that we establiashed at onboarding (*gt_0* and *gt_1*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'counts': {'success': 3000, 'failure': 0, 'total': 3000}, 'failures': [[]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arthur_model.send_batch_ground_truths(data=ground_truth_df)\n",
    "# Can also supply the directory with the ground truth parquet files\n",
    "# arthur_model.send_batch_ground_truths(directory_path=f\"{file_loc}/ground_truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
