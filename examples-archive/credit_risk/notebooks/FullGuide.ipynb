{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T19:08:14.390559Z",
     "start_time": "2021-09-02T19:08:12.824796Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from arthurai import ArthurAI\n",
    "from arthurai.common.constants import InputType, OutputType, Stage\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from model_utils import load_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this guide, we'll use the credit dataset (and a pre-trained model) to onboard a new model to the Arthur platform. We'll walk through registering the model using a sample of the training data. This is an example of a streaming model. We'll also mark a few specific attributes to be monitored for Bias. And we will enable Explainability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up connection\n",
    "Supply your API Key below to authenticate with the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingParameterError",
     "evalue": "Please set api key and url either via environment variables (`ARTHUR_API_KEY` and `ARTHUR_ENDPOINT_URL`) or by passing parameters `access_key` and `url`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hl/bdslq5454bx2hb8xz6s19ggm0000gn/T/ipykernel_31890/3435718308.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# credentials are being passed to the client via environment variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArthurAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/databricks/lib/python3.8/site-packages/arthurai/client/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, verify_ssl, url, access_key, offline, login, password, organization_id)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccess_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservice_account\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             self.client = new_requests_client(access_key=access_key, url=url, verify_ssl=self.verify_ssl,\n\u001b[0m\u001b[1;32m    102\u001b[0m                                               offline=offline, organization_id=organization_id)\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/databricks/lib/python3.8/site-packages/arthurai/client/client.py\u001b[0m in \u001b[0;36mnew_requests_client\u001b[0;34m(access_key, url, verify_ssl, offline, organization_id)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0maccess_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         raise MissingParameterError(\"Please set api key and url either via environment variables \"\n\u001b[0m\u001b[1;32m     37\u001b[0m                                     \u001b[0;34m\"(`ARTHUR_API_KEY` and `ARTHUR_ENDPOINT_URL`) or by passing parameters \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                                     \"`access_key` and `url`.\")\n",
      "\u001b[0;31mMissingParameterError\u001b[0m: Please set api key and url either via environment variables (`ARTHUR_API_KEY` and `ARTHUR_ENDPOINT_URL`) or by passing parameters `access_key` and `url`."
     ]
    }
   ],
   "source": [
    "# credentials are being passed to the client via environment variables\n",
    "connection = ArthurAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T19:08:14.642122Z",
     "start_time": "2021-09-02T19:08:14.567710Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = load_datasets(\"../fixtures/datasets/credit_card_default.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T19:08:17.299377Z",
     "start_time": "2021-09-02T19:08:17.293749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584      0\n",
       "17832    0\n",
       "11647    0\n",
       "1234     0\n",
       "9561     0\n",
       "Name: default payment next month, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T19:08:17.862562Z",
     "start_time": "2021-09-02T19:08:17.842913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49111</td>\n",
       "      <td>48943</td>\n",
       "      <td>45775</td>\n",
       "      <td>0</td>\n",
       "      <td>2200</td>\n",
       "      <td>1600</td>\n",
       "      <td>1700</td>\n",
       "      <td>1700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17832</th>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29991</td>\n",
       "      <td>29192</td>\n",
       "      <td>28210</td>\n",
       "      <td>28543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1100</td>\n",
       "      <td>1300</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11647</th>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>97369</td>\n",
       "      <td>98232</td>\n",
       "      <td>97752</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>43000</td>\n",
       "      <td>5000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>280000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>263734</td>\n",
       "      <td>268216</td>\n",
       "      <td>262895</td>\n",
       "      <td>264508</td>\n",
       "      <td>11000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10004</td>\n",
       "      <td>10020</td>\n",
       "      <td>10100</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>100000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86981</td>\n",
       "      <td>81522</td>\n",
       "      <td>81171</td>\n",
       "      <td>79766</td>\n",
       "      <td>3151</td>\n",
       "      <td>3065</td>\n",
       "      <td>2892</td>\n",
       "      <td>2936</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "584        50000    1          2         2   42      0      0      0      0   \n",
       "17832      30000    1          2         2   24      2      4      3      2   \n",
       "11647     100000    1          2         2   26      0      0      0      0   \n",
       "1234      280000    2          1         2   30      0      0      0      0   \n",
       "9561      100000    2          3         2   27      0      0      0      0   \n",
       "\n",
       "       PAY_5  ...  BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  \\\n",
       "584        0  ...      49111      48943      45775          0      2200   \n",
       "17832      0  ...      29991      29192      28210      28543         0   \n",
       "11647      0  ...      97369      98232      97752          0     10000   \n",
       "1234       0  ...     263734     268216     262895     264508     11000   \n",
       "9561       0  ...      86981      81522      81171      79766      3151   \n",
       "\n",
       "       PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "584        1600      1700      1700         0         0  \n",
       "17832         0         0      1100      1300      2000  \n",
       "11647     43000      5000      3000         0         0  \n",
       "1234      10000     10004     10020     10100     10000  \n",
       "9561       3065      2892      2936      3000      3000  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T19:08:20.451589Z",
     "start_time": "2021-09-02T19:08:19.113582Z"
    }
   },
   "outputs": [],
   "source": [
    "# load our pre-trained classifier so we can generate predictions\n",
    "sk_model = joblib.load(\"../fixtures/serialized_models/credit_model.pkl\")\n",
    "\n",
    "# get model predictions\n",
    "preds = sk_model.predict_proba(X_train)\n",
    "X_train[\"prediction_1\"] = preds[:, 1]\n",
    "\n",
    "# # get ground truth labels\n",
    "X_train[\"gt\"] = Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll instantiate a model object with a small amount of metadata about the model input and output types. Then, we'll use a sample of the training data to register the full data schema for this Tabular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T19:08:20.533507Z",
     "start_time": "2021-09-02T19:08:20.531272Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arthur_model = connection.model(partner_model_id=f\"CreditRiskModel_FG_{datetime.now().strftime('%Y%m%d%H%M%S')}\",\n",
    "                                display_name=\"Credit Risk\",\n",
    "                                input_type=InputType.Tabular,\n",
    "                                output_type=OutputType.Multiclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register the schema for the outputs of the model: what will a typical prediction look like and what will a typical ground truth look like? What names, shapes, and datatypes should Arthur expect for these objects?\n",
    "\n",
    "We'll do this all in one step with the *.build()* method. All we need to supply is:\n",
    "  * the training dataframe\n",
    "  * the mapping that related predictions to ground truth\n",
    "  * positive predicted attribute label\n",
    "  \n",
    "Our classifier will be making predictions about class *0* and class *1* and will return a probability score for each class. Therefore, we'll set up a name *prediction_0* and a name *prediction_1*. Additionally, our groundtruth will be either a 0 or 1, but we'll always represent ground truth in the one-hot-endoded form. Therefore, we create two fields called *gt_0* and *gt_1*. We link these all up in a dictionary and pass that to the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T19:08:22.654494Z",
     "start_time": "2021-09-02T19:08:22.503579Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Map our prediction attribute to the ground truth value\n",
    "prediction_to_ground_truth_map = {\n",
    "    \"prediction_1\": 1\n",
    "}\n",
    "\n",
    "arthur_model.build(X_train, \n",
    "                   ground_truth_column=\"gt\",\n",
    "                   pred_to_ground_truth_map=prediction_to_ground_truth_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Monitoring\n",
    "\n",
    "Next, we will specify that a few attributes (SEX, AGE, and EDUCATION) should be monitored for Bias. We can do this for either categorical or continuous attributes. In the case of continuos attributes, we will breakup the continuous range into bins by providing cutoff values. For more details, please see the [Bias Guide](https://docs.arthur.ai/user-guide/bias.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arthur_model.get_attribute(\"SEX\", stage=Stage.ModelPipelineInput).monitor_for_bias = True\n",
    "arthur_model.get_attribute(\"EDUCATION\", stage=Stage.ModelPipelineInput).monitor_for_bias = True\n",
    "arthur_model.get_attribute(\"AGE\",stage=Stage.ModelPipelineInput).monitor_for_bias = True\n",
    "arthur_model.get_attribute(\"AGE\", stage=Stage.ModelPipelineInput).set(bins = [None, 35, 55, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for ease of reading and later use, we can optionally supply human-readable labels for the values of the attributes. As an example, if we have a column for Age and it is encoded as integers 1 and 2, we can provide a human-readable mapping with string names so that things are easier to understand in the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arthur_model.set_attribute_labels(attribute_name=\"SEX\",\n",
    "                            labels={1: \"Male\", 2: \"Female\"})\n",
    "arthur_model.set_attribute_labels(attribute_name=\"EDUCATION\",\n",
    "                            labels={1: \"Graduate School\", 2: \"University\",\n",
    "                                    3: \"High School\", 4: \"Less Than High School\",\n",
    "                                    5: \"Unknown\", 6: \"Unreported\", 0: \"Other\"})\n",
    "arthur_model.set_attribute_labels(attribute_name=\"MARRIAGE\",\n",
    "                            labels={1: \"Married\", 2: \"Single\",\n",
    "                                    3: \"Other\", 0: \"Unknown\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before saving, be sure to review your model to make sure everything is correct.\n",
    "\n",
    "When saving your model, the data is saved as the reference set, which is used as the baseline data for tracking data drift. Often, this is the training data for the associated model. Our reference dataset should include:\n",
    "  * inputs \n",
    "  * ground truth\n",
    "  * model predictions\n",
    "  \n",
    "This way, Arthur can monitor for drift and stability in all of these aspects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arthur_model.review()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before saving, you can also review your model to make sure everything is correct from the output of `arthur_model.build()` or via `arthur_model.review()`.\n",
    "\n",
    "When saving your model, the data is saved as the reference set, which is used as the baseline data for tracking data drift. Often, this is the training data for the associated model. Our reference dataset should include:\n",
    "  * inputs \n",
    "  * ground truth\n",
    "  * model predictions\n",
    "  \n",
    "This way, Arthur can monitor for drift and stability in all of these aspects. \n",
    "\n",
    "If you've already created your model, you can fetch it from the Arthur API. Retrieve a Model ID from the output of the `arthur_model.save()` call below, or the URL of your model page in the Arthur Dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = arthur_model.save()\n",
    "with open(\"fullguide_model_id.txt\", \"w\") as f:\n",
    "    f.write(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can fetch a model by ID. for example pull the last-created model:\n",
    "# with open(\"fullguide_model_id.txt\", \"r\") as f:\n",
    "#     model_id = f.read()\n",
    "# arthur_model = connection.get_model(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Explainability\n",
    "\n",
    "Next, we will enable Explainability. We will point to an environment requirements file and an entrypoint file. For more details, please see https://docs.arthur.ai/user-guide/explainability.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring folder: /Users/karthik/Documents/Arthur/arthur-sandbox/examples/example_projects/credit_risk\n",
      "Ignoring folder: /Users/karthik/Documents/Arthur/arthur-sandbox/examples/example_projects/credit_risk/__pycache__\n",
      "Ignoring folder: /Users/karthik/Documents/Arthur/arthur-sandbox/examples/example_projects/credit_risk/fixtures\n",
      "Ignoring folder: /Users/karthik/Documents/Arthur/arthur-sandbox/examples/example_projects/credit_risk/fixtures/serialized_models\n",
      "Ignoring folder: /Users/karthik/Documents/Arthur/arthur-sandbox/examples/example_projects/credit_risk/fixtures/datasets\n",
      "Ignoring folder: /Users/karthik/Documents/Arthur/arthur-sandbox/examples/example_projects/credit_risk/notebooks\n",
      "Ignoring folder: /Users/karthik/Documents/Arthur/arthur-sandbox/examples/example_projects/credit_risk/notebooks/.ipynb_checkpoints\n"
     ]
    },
    {
     "ename": "UserValueError",
     "evalue": "Failed to validate requirements file: \nExplainability requirements file lists joblib==1.1.0 but found version 1.0.1 currently installed. Packages listed in the requirements file must match the currently installed version. To resolve, update the requirements file to version joblib==1.0.1\nExplainability requirements file lists numpy==1.20.3 but found version 1.20.1 currently installed. Packages listed in the requirements file must match the currently installed version. To resolve, update the requirements file to version numpy==1.20.1\nExplainability requirements file lists pandas==1.1.4 but found version 1.2.1 currently installed. Packages listed in the requirements file must match the currently installed version. To resolve, update the requirements file to version pandas==1.2.1\nExplainability requirements file lists pytz==2021.3 but found version 2021.1 currently installed. Packages listed in the requirements file must match the currently installed version. To resolve, update the requirements file to version pytz==2021.1\nExplainability requirements file lists scikit-learn==1.0.1 but found version 0.24.2 currently installed. Packages listed in the requirements file must match the currently installed version. To resolve, update the requirements file to version scikit-learn==0.24.2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUserValueError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hl/bdslq5454bx2hb8xz6s19ggm0000gn/T/ipykernel_31890/410289352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m arthur_model.enable_explainability(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mproject_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/databricks/lib/python3.8/site-packages/arthurai/common/exceptions.py\u001b[0m in \u001b[0;36mwrapper_arthur_excepted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# if it is a user error simply re-raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArthurUserError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;31m# otherwise wrap it in a message saying it's not the user's fault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArthurInternalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/databricks/lib/python3.8/site-packages/arthurai/common/exceptions.py\u001b[0m in \u001b[0;36mwrapper_arthur_excepted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# call the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;31m# if it is a user error simply re-raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArthurUserError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/databricks/lib/python3.8/site-packages/arthurai/core/models.py\u001b[0m in \u001b[0;36menable_explainability\u001b[0;34m(self, df, project_directory, user_predict_function_import_path, streaming_explainability_enabled, requirements_file, python_version, sdk_version, model_server_num_cpu, model_server_memory, model_server_max_replicas, inference_consumer_num_cpu, inference_consumer_memory, inference_consumer_thread_pool_size, inference_consumer_score_percent, explanation_nsamples, explanation_algo, ignore_dirs)\u001b[0m\n\u001b[1;32m   1463\u001b[0m             \u001b[0minference_consumer_score_percent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minference_consumer_score_percent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m         )\n\u001b[0;32m-> 1465\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_enrichment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnrichment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExplainability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplainability_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0marthur_excepted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"failed to enable bias mitigation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/databricks/lib/python3.8/site-packages/arthurai/common/exceptions.py\u001b[0m in \u001b[0;36mwrapper_arthur_excepted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# if it is a user error simply re-raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArthurUserError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;31m# otherwise wrap it in a message saying it's not the user's fault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArthurInternalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/databricks/lib/python3.8/site-packages/arthurai/common/exceptions.py\u001b[0m in \u001b[0;36mwrapper_arthur_excepted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# call the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;31m# if it is a user error simply re-raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArthurUserError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/databricks/lib/python3.8/site-packages/arthurai/core/models.py\u001b[0m in \u001b[0;36mupdate_enrichment\u001b[0;34m(self, enrichment, enabled, config)\u001b[0m\n\u001b[1;32m   2941\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2943\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_enrichments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0menrichment\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0marthur_excepted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"failed to enable hotspots\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/databricks/lib/python3.8/site-packages/arthurai/common/exceptions.py\u001b[0m in \u001b[0;36mwrapper_arthur_excepted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# if it is a user error simply re-raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArthurUserError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;31m# otherwise wrap it in a message saying it's not the user's fault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArthurInternalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/databricks/lib/python3.8/site-packages/arthurai/common/exceptions.py\u001b[0m in \u001b[0;36mwrapper_arthur_excepted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# call the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;31m# if it is a user error simply re-raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArthurUserError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/databricks/lib/python3.8/site-packages/arthurai/core/models.py\u001b[0m in \u001b[0;36mupdate_enrichments\u001b[0;34m(self, enrichment_configs)\u001b[0m\n\u001b[1;32m   2910\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mallPresent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m                 \u001b[0mexplanationPackager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m                 \u001b[0mexplanationPackager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m                 \u001b[0mfiles\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mexplanationPackager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_request_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m             \u001b[0;31m# replace passed in config (has file specific fields) with actual config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/databricks/lib/python3.8/site-packages/arthurai/explainability/explanation_packager.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_file_errors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0merror_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_file_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUserValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to validate requirements file: {error_str}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_predict_function_import_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUserValueError\u001b[0m: Failed to validate requirements file: \nExplainability requirements file lists joblib==1.1.0 but found version 1.0.1 currently installed. Packages listed in the requirements file must match the currently installed version. To resolve, update the requirements file to version joblib==1.0.1\nExplainability requirements file lists numpy==1.20.3 but found version 1.20.1 currently installed. Packages listed in the requirements file must match the currently installed version. To resolve, update the requirements file to version numpy==1.20.1\nExplainability requirements file lists pandas==1.1.4 but found version 1.2.1 currently installed. Packages listed in the requirements file must match the currently installed version. To resolve, update the requirements file to version pandas==1.2.1\nExplainability requirements file lists pytz==2021.3 but found version 2021.1 currently installed. Packages listed in the requirements file must match the currently installed version. To resolve, update the requirements file to version pytz==2021.1\nExplainability requirements file lists scikit-learn==1.0.1 but found version 0.24.2 currently installed. Packages listed in the requirements file must match the currently installed version. To resolve, update the requirements file to version scikit-learn==0.24.2"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = Path(os.getcwd())\n",
    "arthur_model.enable_explainability(\n",
    "    df=X_train,\n",
    "    project_directory=path.parents[0],\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    user_predict_function_import_path=\"xai_entrypoint\",\n",
    "    explanation_algo=\"lime\",\n",
    "    streaming_explainability_enabled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However you are currently invoking your model's prediction (eg. through a .predict() or .predict_proba() call), you can wrap this call so that the inputs and outputs are logged with Arthur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arthurai.core.decorators import log_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_prediction(arthur_model)\n",
    "def model_predict(input_vec):\n",
    " return sk_model.predict_proba(input_vec)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T22:02:22.489559Z",
     "start_time": "2021-08-02T22:02:22.481988Z"
    }
   },
   "source": [
    "We'll create some timestamps to mimic sending the data over a period of time. If these are left out the\n",
    "current time will be populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T22:03:09.216312Z",
     "start_time": "2021-08-02T22:03:09.213325Z"
    }
   },
   "outputs": [],
   "source": [
    "# 10 timestamps over the last month\n",
    "timestamps = pd.date_range(start=datetime.now(pytz.utc) - timedelta(days=30),\n",
    "                           end=datetime.now(pytz.utc),\n",
    "                           periods=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we iterate through a dataset and invoke our model for predictions, the model inputs and outputs are logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_ids = {}\n",
    "for timestamp in timestamps:\n",
    "    for i in range(np.random.randint(7, 10)):\n",
    "        datarecord = X_test.sample(1)  # fetch a random row\n",
    "        prediction, inference_id = model_predict(datarecord, inference_timestamp=timestamp)  # predict and log\n",
    "        inference_ids[inference_id] = datarecord.index[0]  # record the inference ID with the Pandas index\n",
    "    print(f\"Logged {i+1} inferences with Arthur from {timestamp.strftime('%m/%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If your model scoring system is a set up in a batch processor where you run a daily, weekly, or monthly job, then we recommend setting a batch model with Arthur and using the corresponding *send_batch_inferences()* method. An example batch model can be found [here](../../credit_risk_batch/notebooks/Quickstart.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating with Ground Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future, when your ground truth lables come in, you can [update each inference](https://docs.arthur.ai/sdk/sdk_v3/arthurai.core.html#arthurai.core.models.ArthurModel.update_inference_ground_truths) by id with its corresponding label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T21:54:20.699496Z",
     "start_time": "2021-08-02T21:54:20.689864Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inference_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hl/bdslq5454bx2hb8xz6s19ggm0000gn/T/ipykernel_31890/613359031.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m gt_df = pd.DataFrame({'partner_inference_id': inference_ids.keys(),\n\u001b[0m\u001b[1;32m      2\u001b[0m                       'gt': Y_test[inference_ids.values()]})\n\u001b[1;32m      3\u001b[0m \u001b[0mgt_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inference_ids' is not defined"
     ]
    }
   ],
   "source": [
    "gt_df = pd.DataFrame({'partner_inference_id': inference_ids.keys(),\n",
    "                      'gt': Y_test[inference_ids.values()]})\n",
    "gt_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T21:54:41.573703Z",
     "start_time": "2021-08-02T21:54:41.363026Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = arthur_model.update_inference_ground_truths(gt_df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d485cb42aaa05640787d51ff6b98576e6591c8fe1b0e087ca1599e137e7b48f2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
